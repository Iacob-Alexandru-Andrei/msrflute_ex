WORLD_SIZE=5
MASTER_ADDR=mauao
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'num_frames', 'max_grad_norm', 'unsorted_batch', 'num_workers', 'prepend_datapath', 'max_batch_size', 'pin_memory'} in [server_config][val][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'pin_memory', 'num_frames', 'max_grad_norm', 'unsorted_batch', 'num_workers', 'prepend_datapath', 'max_batch_size'} in [server_config][test][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'num_frames', 'max_grad_norm', 'unsorted_batch', 'num_workers', 'prepend_datapath', 'max_batch_size', 'pin_memory'} in [client_config][train][data_config]
Sat Jun  3 02:03:53 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:03:53 2023 : Backend: nccl
Sat Jun  3 02:03:53 2023 : WORLD_RANK: 1
Sat Jun  3 02:03:53 2023 : LOCAL_RANK: 1
Sat Jun  3 02:03:53 2023 : NODE_NAME: mauao
Sat Jun  3 02:03:53 2023 : LOCAL_RANK_LIMIT: 2
Sat Jun  3 02:03:53 2023 : Passed
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'prepend_datapath', 'unsorted_batch', 'max_batch_size', 'max_grad_norm', 'num_workers', 'num_frames', 'pin_memory'} in [server_config][val][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'prepend_datapath', 'unsorted_batch', 'max_batch_size', 'max_grad_norm', 'num_workers', 'num_frames', 'pin_memory'} in [server_config][test][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'prepend_datapath', 'num_frames', 'unsorted_batch', 'pin_memory', 'max_batch_size', 'max_grad_norm', 'num_workers'} in [client_config][train][data_config]
Sat Jun  3 02:03:53 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:03:53 2023 : Backend: nccl
Sat Jun  3 02:03:53 2023 : WORLD_RANK: 2
Sat Jun  3 02:03:53 2023 : LOCAL_RANK: 2
Sat Jun  3 02:03:53 2023 : NODE_NAME: mauao
Sat Jun  3 02:03:53 2023 : LOCAL_RANK_LIMIT: 2
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'max_batch_size', 'pin_memory', 'num_workers', 'max_grad_norm', 'num_frames', 'prepend_datapath', 'unsorted_batch'} in [server_config][val][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'max_batch_size', 'pin_memory', 'num_workers', 'num_frames', 'max_grad_norm', 'prepend_datapath', 'unsorted_batch'} in [server_config][test][data_config]
Sat Jun  3 02:03:53 2023 : Assigning default values for: {'max_batch_size', 'pin_memory', 'prepend_datapath', 'num_workers', 'num_frames', 'max_grad_norm', 'unsorted_batch'} in [client_config][train][data_config]
Sat Jun  3 02:03:53 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:03:53 2023 : Backend: nccl
Sat Jun  3 02:03:53 2023 : WORLD_RANK: 0
Sat Jun  3 02:03:53 2023 : LOCAL_RANK: 0
Sat Jun  3 02:03:53 2023 : NODE_NAME: mauao
Sat Jun  3 02:03:53 2023 : LOCAL_RANK_LIMIT: 2
Sat Jun  3 02:03:53 2023 : Passed

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: mauao: task 2: Exited with exit code 2
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Added key: store_based_barrier_key:1 to store for rank: 1
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'num_frames', 'max_grad_norm', 'pin_memory', 'max_batch_size', 'prepend_datapath', 'num_workers', 'unsorted_batch'} in [server_config][val][data_config]
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'num_frames', 'max_grad_norm', 'pin_memory', 'max_batch_size', 'prepend_datapath', 'num_workers', 'unsorted_batch'} in [server_config][test][data_config]
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'num_frames', 'pin_memory', 'max_batch_size', 'prepend_datapath', 'num_workers', 'max_grad_norm', 'unsorted_batch'} in [client_config][train][data_config]
Sat Jun  3 02:03:55 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:03:55 2023 : Backend: nccl
Sat Jun  3 02:03:55 2023 : WORLD_RANK: 4
Sat Jun  3 02:03:55 2023 : LOCAL_RANK: 1
Sat Jun  3 02:03:55 2023 : NODE_NAME: ngongotaha
Sat Jun  3 02:03:55 2023 : LOCAL_RANK_LIMIT: 3
Sat Jun  3 02:03:55 2023 : Passed
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'num_workers', 'prepend_datapath', 'num_frames', 'unsorted_batch', 'pin_memory', 'max_batch_size', 'max_grad_norm'} in [server_config][val][data_config]
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'num_workers', 'prepend_datapath', 'num_frames', 'unsorted_batch', 'pin_memory', 'max_batch_size', 'max_grad_norm'} in [server_config][test][data_config]
Sat Jun  3 02:03:55 2023 : Assigning default values for: {'prepend_datapath', 'num_workers', 'num_frames', 'unsorted_batch', 'pin_memory', 'max_batch_size', 'max_grad_norm'} in [client_config][train][data_config]
Sat Jun  3 02:03:55 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:03:55 2023 : Backend: nccl
Sat Jun  3 02:03:55 2023 : WORLD_RANK: 2
Sat Jun  3 02:03:55 2023 : LOCAL_RANK: 2
Sat Jun  3 02:03:55 2023 : NODE_NAME: ngongotaha
Sat Jun  3 02:03:55 2023 : LOCAL_RANK_LIMIT: 3
Sat Jun  3 02:03:55 2023 : Passed
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 4
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Sat Jun  3 02:04:00 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'prepend_datapath', 'num_workers', 'pin_memory', 'max_grad_norm', 'unsorted_batch'} in [server_config][val][data_config]
Sat Jun  3 02:04:00 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'prepend_datapath', 'num_workers', 'pin_memory', 'max_grad_norm', 'unsorted_batch'} in [server_config][test][data_config]
Sat Jun  3 02:04:00 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'max_grad_norm', 'prepend_datapath', 'num_workers', 'pin_memory', 'unsorted_batch'} in [client_config][train][data_config]
Sat Jun  3 02:04:00 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Sat Jun  3 02:04:00 2023 : Backend: nccl
Sat Jun  3 02:04:00 2023 : WORLD_RANK: 3
Sat Jun  3 02:04:00 2023 : LOCAL_RANK: 0
Sat Jun  3 02:04:00 2023 : NODE_NAME: ngongotaha
Sat Jun  3 02:04:00 2023 : LOCAL_RANK_LIMIT: 3
Sat Jun  3 02:04:00 2023 : Passed
Added key: store_based_barrier_key:1 to store for rank: 3
Added key: store_based_barrier_key:1 to store for rank: 0
Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 5 nodes.
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 5 nodes.
Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 5 nodes.
Sat Jun  3 02:04:00 2023 : Assigning worker to GPU 2
Sat Jun  3 02:04:00 2023 : Assigning worker to GPU 1
Group initialized? True
Sat Jun  3 02:04:00 2023 : Master_node: mauao
Sat Jun  3 02:04:00 2023 : Assigning worker to GPU 0
Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 5 nodes.
Sat Jun  3 02:04:00 2023 : Assigning worker to GPU 1
Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 5 nodes.
Sat Jun  3 02:04:00 2023 : Assigning worker to GPU 0
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:01 2023 : initialize model with default settings
Sat Jun  3 02:04:01 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:01 2023 : initialize model with default settings
Sat Jun  3 02:04:01 2023 : trying to move the model to GPU
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:01 2023 : initialize model with default settings
Sat Jun  3 02:04:01 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:01 2023 : initialize model with default settings
Sat Jun  3 02:04:01 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:01 2023 : initialize model with default settings
Sat Jun  3 02:04:01 2023 : trying to move the model to GPU
Sat Jun  3 02:04:04 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_allocated(): 29774336
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_cached(): 35651584
Sat Jun  3 02:04:04 2023 : torch.cuda.synchronize(): None
Sat Jun  3 02:04:04 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_allocated(): 29774336
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_cached(): 35651584
Sat Jun  3 02:04:04 2023 : torch.cuda.synchronize(): None
Sat Jun  3 02:04:04 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_allocated(): 29774336
Sat Jun  3 02:04:04 2023 : torch.cuda.memory_cached(): 35651584
Sat Jun  3 02:04:04 2023 : torch.cuda.synchronize(): None
Sat Jun  3 02:04:05 2023 : Worker on node 4: process started
Sat Jun  3 02:04:05 2023 : Worker on node 2: process started
Sat Jun  3 02:04:05 2023 : Worker on node 3: process started
Sat Jun  3 02:04:07 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:07 2023 : torch.cuda.memory_allocated(): 29774336
Sat Jun  3 02:04:07 2023 : torch.cuda.memory_cached(): 35651584
Sat Jun  3 02:04:07 2023 : torch.cuda.synchronize(): None
Sat Jun  3 02:04:08 2023 : Server data preparation
Sat Jun  3 02:04:08 2023 : Prepared the dataloaders
Sat Jun  3 02:04:08 2023 : Loading Model from: None
Sat Jun  3 02:04:08 2023 : Using fast aggregation
Could not load the run context. Logging offline
Attempted to log scalar metric System memory (GB):
755.5415306091309
Attempted to log scalar metric server_config.num_clients_per_iteration:
100
Attempted to log scalar metric server_config.max_iteration:
100
Attempted to log scalar metric dp_config.eps:
0
Attempted to log scalar metric dp_config.max_weight:
0
Attempted to log scalar metric dp_config.min_weight:
0
Attempted to log scalar metric server_config.optimizer_config.type:
sgd
Attempted to log scalar metric server_config.optimizer_config.lr:
1.0
Attempted to log scalar metric server_config.optimizer_config.amsgrad:
False
Attempted to log scalar metric server_config.annealing_config.type:
none
Attempted to log scalar metric server_config.annealing_config.step_interval:
epoch
Attempted to log scalar metric server_config.annealing_config.gamma:
1.0
Attempted to log scalar metric server_config.annealing_config.step_size:
5000000
Sat Jun  3 02:04:08 2023 : Launching server
Sat Jun  3 02:04:08 2023 : server started
Attempted to log scalar metric Max iterations:
100
Sat Jun  3 02:04:08 2023 : Running [] at itr=0
Sat Jun  3 02:04:08 2023 : Saving Model Before Starting Training
Sat Jun  3 02:04:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/best_val_loss_model.tar
Sat Jun  3 02:04:08 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Sat Jun  3 02:04:08 2023 : torch.cuda.memory_allocated(): 29774336
Sat Jun  3 02:04:08 2023 : torch.cuda.memory_cached(): 35651584
Sat Jun  3 02:04:08 2023 : torch.cuda.synchronize(): None
Sat Jun  3 02:04:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/best_val_acc_model.tar
Sat Jun  3 02:04:09 2023 : Worker on node 1: process started
Sat Jun  3 02:04:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/best_test_acc_model.tar
Sat Jun  3 02:04:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:04:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:04:12 2023 : ==== iteration 0
Sat Jun  3 02:04:12 2023 : Client learning rate 0.1
Sat Jun  3 02:04:12 2023 : Clients for round 100
Sat Jun  3 02:06:06 2023 : Updating model
Sat Jun  3 02:06:06 2023 : Updating learning rate scheduler
Sat Jun  3 02:06:06 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:06:06 2023 : Run ss scheduler
Sat Jun  3 02:06:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:06:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:06:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:06:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch0_model.tar
Sat Jun  3 02:06:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:06:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:06:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch0_best_val_acc_model.tar
Sat Jun  3 02:06:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch0_best_val_loss_model.tar
Sat Jun  3 02:06:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch0_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
0
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1899.6946144104004
Attempted to log scalar metric secsPerRoundTotal:
118.46029710769653
Sat Jun  3 02:06:10 2023 : ==== iteration 1
Sat Jun  3 02:06:10 2023 : Client learning rate 0.1
Sat Jun  3 02:06:10 2023 : Clients for round 100
Sat Jun  3 02:09:11 2023 : Updating model
Sat Jun  3 02:09:11 2023 : Updating learning rate scheduler
Sat Jun  3 02:09:11 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:09:11 2023 : Run ss scheduler
Sat Jun  3 02:09:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:09:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:09:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:09:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch1_model.tar
Sat Jun  3 02:09:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:09:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:09:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch1_best_val_acc_model.tar
Sat Jun  3 02:09:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch1_best_val_loss_model.tar
Sat Jun  3 02:09:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch1_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
1
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2225.1483857631683
Attempted to log scalar metric secsPerRoundTotal:
184.80681085586548
Sat Jun  3 02:09:15 2023 : ==== iteration 2
Sat Jun  3 02:09:15 2023 : Client learning rate 0.1
Sat Jun  3 02:09:15 2023 : Clients for round 100
Sat Jun  3 02:11:44 2023 : Updating model
Sat Jun  3 02:11:44 2023 : Updating learning rate scheduler
Sat Jun  3 02:11:44 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:11:44 2023 : Run ss scheduler
Sat Jun  3 02:11:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:11:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:11:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:11:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch2_model.tar
Sat Jun  3 02:11:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:11:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:11:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch2_best_val_acc_model.tar
Sat Jun  3 02:11:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch2_best_val_loss_model.tar
Sat Jun  3 02:11:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch2_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
2
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1772.522208929062
Attempted to log scalar metric secsPerRoundTotal:
152.85955810546875
Sat Jun  3 02:11:48 2023 : ==== iteration 3
Sat Jun  3 02:11:48 2023 : Client learning rate 0.1
Sat Jun  3 02:11:48 2023 : Clients for round 100
Sat Jun  3 02:15:02 2023 : Updating model
Sat Jun  3 02:15:02 2023 : Updating learning rate scheduler
Sat Jun  3 02:15:02 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:15:02 2023 : Run ss scheduler
Sat Jun  3 02:15:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:15:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:15:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:15:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch3_model.tar
Sat Jun  3 02:15:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:15:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:15:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch3_best_val_acc_model.tar
Sat Jun  3 02:15:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch3_best_val_loss_model.tar
Sat Jun  3 02:15:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch3_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
3
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2368.5836856365204
Attempted to log scalar metric secsPerRoundTotal:
199.12731194496155
Sat Jun  3 02:15:07 2023 : ==== iteration 4
Sat Jun  3 02:15:07 2023 : Client learning rate 0.1
Sat Jun  3 02:15:07 2023 : Clients for round 100
Sat Jun  3 02:18:24 2023 : Updating model
Sat Jun  3 02:18:24 2023 : Updating learning rate scheduler
Sat Jun  3 02:18:24 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:18:24 2023 : Run ss scheduler
Sat Jun  3 02:18:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:18:25 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:18:25 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:18:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch4_model.tar
Sat Jun  3 02:18:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:18:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:18:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch4_best_val_acc_model.tar
Sat Jun  3 02:18:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch4_best_val_loss_model.tar
Sat Jun  3 02:18:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch4_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
4
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2212.725387573242
Attempted to log scalar metric secsPerRoundTotal:
201.45683884620667
Sat Jun  3 02:18:29 2023 : ==== iteration 5
Sat Jun  3 02:18:29 2023 : Client learning rate 0.1
Sat Jun  3 02:18:29 2023 : Clients for round 100
Sat Jun  3 02:21:52 2023 : Updating model
Sat Jun  3 02:21:52 2023 : Updating learning rate scheduler
Sat Jun  3 02:21:52 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:21:52 2023 : Run ss scheduler
Sat Jun  3 02:21:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:21:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:21:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:21:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch5_model.tar
Sat Jun  3 02:21:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:21:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:21:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch5_best_val_acc_model.tar
Sat Jun  3 02:21:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch5_best_val_loss_model.tar
Sat Jun  3 02:21:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch5_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
5
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2346.5437371730804
Attempted to log scalar metric secsPerRoundTotal:
207.98779344558716
Sat Jun  3 02:21:57 2023 : ==== iteration 6
Sat Jun  3 02:21:57 2023 : Client learning rate 0.1
Sat Jun  3 02:21:57 2023 : Clients for round 100
Sat Jun  3 02:25:12 2023 : Updating model
Sat Jun  3 02:25:12 2023 : Updating learning rate scheduler
Sat Jun  3 02:25:12 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:25:12 2023 : Run ss scheduler
Sat Jun  3 02:25:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:25:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:25:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:25:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch6_model.tar
Sat Jun  3 02:25:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:25:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:25:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch6_best_val_acc_model.tar
Sat Jun  3 02:25:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch6_best_val_loss_model.tar
Sat Jun  3 02:25:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch6_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
6
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1973.933357000351
Attempted to log scalar metric secsPerRoundTotal:
199.89688873291016
Sat Jun  3 02:25:17 2023 : ==== iteration 7
Sat Jun  3 02:25:17 2023 : Client learning rate 0.1
Sat Jun  3 02:25:17 2023 : Clients for round 100
Sat Jun  3 02:28:30 2023 : Updating model
Sat Jun  3 02:28:30 2023 : Updating learning rate scheduler
Sat Jun  3 02:28:30 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:28:30 2023 : Run ss scheduler
Sat Jun  3 02:28:30 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:28:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:28:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:28:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch7_model.tar
Sat Jun  3 02:28:32 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:28:32 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:28:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch7_best_val_acc_model.tar
Sat Jun  3 02:28:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch7_best_val_loss_model.tar
Sat Jun  3 02:28:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch7_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
7
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2353.515789747238
Attempted to log scalar metric secsPerRoundTotal:
197.9567539691925
Sat Jun  3 02:28:35 2023 : ==== iteration 8
Sat Jun  3 02:28:35 2023 : Client learning rate 0.1
Sat Jun  3 02:28:35 2023 : Clients for round 100
Sat Jun  3 02:31:09 2023 : Updating model
Sat Jun  3 02:31:09 2023 : Updating learning rate scheduler
Sat Jun  3 02:31:09 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:31:09 2023 : Run ss scheduler
Sat Jun  3 02:31:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:31:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:31:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:31:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch8_model.tar
Sat Jun  3 02:31:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:31:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:31:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch8_best_val_acc_model.tar
Sat Jun  3 02:31:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch8_best_val_loss_model.tar
Sat Jun  3 02:31:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch8_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
8
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2059.4258930683136
Attempted to log scalar metric secsPerRoundTotal:
159.53231287002563
Sat Jun  3 02:31:14 2023 : ==== iteration 9
Sat Jun  3 02:31:14 2023 : Client learning rate 0.1
Sat Jun  3 02:31:14 2023 : Clients for round 100
Sat Jun  3 02:34:12 2023 : Updating model
Sat Jun  3 02:34:12 2023 : Updating learning rate scheduler
Sat Jun  3 02:34:12 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:34:12 2023 : Run ss scheduler
Sat Jun  3 02:34:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:34:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:34:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:34:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch9_model.tar
Sat Jun  3 02:34:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:34:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:34:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch9_best_val_acc_model.tar
Sat Jun  3 02:34:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch9_best_val_loss_model.tar
Sat Jun  3 02:34:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch9_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
9
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1836.5371243953705
Attempted to log scalar metric secsPerRoundTotal:
182.36072325706482
Sat Jun  3 02:34:16 2023 : ==== iteration 10
Sat Jun  3 02:34:16 2023 : Client learning rate 0.1
Sat Jun  3 02:34:16 2023 : Clients for round 100
Sat Jun  3 02:37:41 2023 : Updating model
Sat Jun  3 02:37:41 2023 : Updating learning rate scheduler
Sat Jun  3 02:37:41 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:37:41 2023 : Run ss scheduler
Sat Jun  3 02:37:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:37:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:37:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:37:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch10_model.tar
Sat Jun  3 02:37:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:37:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:37:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch10_best_val_acc_model.tar
Sat Jun  3 02:37:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch10_best_val_loss_model.tar
Sat Jun  3 02:37:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch10_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
10
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2153.0645654201508
Attempted to log scalar metric secsPerRoundTotal:
208.94473266601562
Sat Jun  3 02:37:45 2023 : ==== iteration 11
Sat Jun  3 02:37:45 2023 : Client learning rate 0.1
Sat Jun  3 02:37:45 2023 : Clients for round 100
Sat Jun  3 02:42:49 2023 : Updating model
Sat Jun  3 02:42:49 2023 : Updating learning rate scheduler
Sat Jun  3 02:42:49 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:42:49 2023 : Run ss scheduler
Sat Jun  3 02:42:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:42:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:42:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:42:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch11_model.tar
Sat Jun  3 02:42:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:42:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:42:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch11_best_val_acc_model.tar
Sat Jun  3 02:42:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch11_best_val_loss_model.tar
Sat Jun  3 02:42:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch11_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
11
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
3542.5141077041626
Attempted to log scalar metric secsPerRoundTotal:
308.1557822227478
Sat Jun  3 02:42:54 2023 : ==== iteration 12
Sat Jun  3 02:42:54 2023 : Client learning rate 0.1
Sat Jun  3 02:42:54 2023 : Clients for round 100
Sat Jun  3 02:45:50 2023 : Updating model
Sat Jun  3 02:45:50 2023 : Updating learning rate scheduler
Sat Jun  3 02:45:50 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:45:50 2023 : Run ss scheduler
Sat Jun  3 02:45:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:45:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:45:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:45:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch12_model.tar
Sat Jun  3 02:45:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:45:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:45:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch12_best_val_acc_model.tar
Sat Jun  3 02:45:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch12_best_val_loss_model.tar
Sat Jun  3 02:45:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch12_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
12
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1858.5311260223389
Attempted to log scalar metric secsPerRoundTotal:
180.90087699890137
Sat Jun  3 02:45:54 2023 : ==== iteration 13
Sat Jun  3 02:45:54 2023 : Client learning rate 0.1
Sat Jun  3 02:45:54 2023 : Clients for round 100
Sat Jun  3 02:48:43 2023 : Updating model
Sat Jun  3 02:48:43 2023 : Updating learning rate scheduler
Sat Jun  3 02:48:43 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:48:43 2023 : Run ss scheduler
Sat Jun  3 02:48:43 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:48:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:48:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:48:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch13_model.tar
Sat Jun  3 02:48:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:48:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:48:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch13_best_val_acc_model.tar
Sat Jun  3 02:48:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch13_best_val_loss_model.tar
Sat Jun  3 02:48:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch13_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
13
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1651.9686138629913
Attempted to log scalar metric secsPerRoundTotal:
172.98600053787231
Sat Jun  3 02:48:47 2023 : ==== iteration 14
Sat Jun  3 02:48:47 2023 : Client learning rate 0.1
Sat Jun  3 02:48:47 2023 : Clients for round 100
Sat Jun  3 02:51:36 2023 : Updating model
Sat Jun  3 02:51:36 2023 : Updating learning rate scheduler
Sat Jun  3 02:51:36 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:51:36 2023 : Run ss scheduler
Sat Jun  3 02:51:36 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:51:37 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:51:37 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:51:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch14_model.tar
Sat Jun  3 02:51:38 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:51:38 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:51:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch14_best_val_acc_model.tar
Sat Jun  3 02:51:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch14_best_val_loss_model.tar
Sat Jun  3 02:51:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch14_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
14
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1869.0501501560211
Attempted to log scalar metric secsPerRoundTotal:
173.5855622291565
Sat Jun  3 02:51:41 2023 : ==== iteration 15
Sat Jun  3 02:51:41 2023 : Client learning rate 0.1
Sat Jun  3 02:51:41 2023 : Clients for round 100
Sat Jun  3 02:54:43 2023 : Updating model
Sat Jun  3 02:54:43 2023 : Updating learning rate scheduler
Sat Jun  3 02:54:43 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:54:43 2023 : Run ss scheduler
Sat Jun  3 02:54:43 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:54:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:54:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:54:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch15_model.tar
Sat Jun  3 02:54:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:54:45 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:54:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch15_best_val_acc_model.tar
Sat Jun  3 02:54:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch15_best_val_loss_model.tar
Sat Jun  3 02:54:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch15_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
15
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1692.4080040454865
Attempted to log scalar metric secsPerRoundTotal:
186.5496311187744
Sat Jun  3 02:54:48 2023 : ==== iteration 16
Sat Jun  3 02:54:48 2023 : Client learning rate 0.1
Sat Jun  3 02:54:48 2023 : Clients for round 100
Sat Jun  3 02:58:40 2023 : Updating model
Sat Jun  3 02:58:40 2023 : Updating learning rate scheduler
Sat Jun  3 02:58:40 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 02:58:40 2023 : Run ss scheduler
Sat Jun  3 02:58:40 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 02:58:41 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:58:41 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:58:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch16_model.tar
Sat Jun  3 02:58:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:58:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 02:58:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch16_best_val_acc_model.tar
Sat Jun  3 02:58:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch16_best_val_loss_model.tar
Sat Jun  3 02:58:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch16_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
16
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2128.5419166088104
Attempted to log scalar metric secsPerRoundTotal:
237.11188626289368
Sat Jun  3 02:58:45 2023 : ==== iteration 17
Sat Jun  3 02:58:45 2023 : Client learning rate 0.1
Sat Jun  3 02:58:45 2023 : Clients for round 100
Sat Jun  3 03:02:41 2023 : Updating model
Sat Jun  3 03:02:41 2023 : Updating learning rate scheduler
Sat Jun  3 03:02:41 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:02:41 2023 : Run ss scheduler
Sat Jun  3 03:02:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:02:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:02:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:02:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch17_model.tar
Sat Jun  3 03:02:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:02:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:02:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch17_best_val_acc_model.tar
Sat Jun  3 03:02:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch17_best_val_loss_model.tar
Sat Jun  3 03:02:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch17_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
17
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1832.1041812896729
Attempted to log scalar metric secsPerRoundTotal:
240.46383690834045
Sat Jun  3 03:02:45 2023 : ==== iteration 18
Sat Jun  3 03:02:45 2023 : Client learning rate 0.1
Sat Jun  3 03:02:45 2023 : Clients for round 100
Sat Jun  3 03:06:14 2023 : Updating model
Sat Jun  3 03:06:14 2023 : Updating learning rate scheduler
Sat Jun  3 03:06:14 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:06:14 2023 : Run ss scheduler
Sat Jun  3 03:06:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:06:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:06:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:06:16 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch18_model.tar
Sat Jun  3 03:06:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:06:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:06:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch18_best_val_acc_model.tar
Sat Jun  3 03:06:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch18_best_val_loss_model.tar
Sat Jun  3 03:06:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch18_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
18
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1996.2958447933197
Attempted to log scalar metric secsPerRoundTotal:
213.77495312690735
Sat Jun  3 03:06:19 2023 : ==== iteration 19
Sat Jun  3 03:06:19 2023 : Client learning rate 0.1
Sat Jun  3 03:06:19 2023 : Clients for round 100
Sat Jun  3 03:09:09 2023 : Updating model
Sat Jun  3 03:09:09 2023 : Updating learning rate scheduler
Sat Jun  3 03:09:09 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:09:09 2023 : Run ss scheduler
Sat Jun  3 03:09:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:09:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:09:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:09:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch19_model.tar
Sat Jun  3 03:09:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:09:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:09:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch19_best_val_acc_model.tar
Sat Jun  3 03:09:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch19_best_val_loss_model.tar
Sat Jun  3 03:09:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch19_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
19
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1819.1061503887177
Attempted to log scalar metric secsPerRoundTotal:
174.01059794425964
Sat Jun  3 03:09:13 2023 : ==== iteration 20
Sat Jun  3 03:09:13 2023 : Client learning rate 0.1
Sat Jun  3 03:09:13 2023 : Clients for round 100
Sat Jun  3 03:12:18 2023 : Updating model
Sat Jun  3 03:12:18 2023 : Updating learning rate scheduler
Sat Jun  3 03:12:18 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:12:18 2023 : Run ss scheduler
Sat Jun  3 03:12:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:12:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:12:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:12:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch20_model.tar
Sat Jun  3 03:12:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:12:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:12:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch20_best_val_acc_model.tar
Sat Jun  3 03:12:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch20_best_val_loss_model.tar
Sat Jun  3 03:12:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch20_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
20
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1555.9638452529907
Attempted to log scalar metric secsPerRoundTotal:
189.666419506073
Sat Jun  3 03:12:23 2023 : ==== iteration 21
Sat Jun  3 03:12:23 2023 : Client learning rate 0.1
Sat Jun  3 03:12:23 2023 : Clients for round 100
Sat Jun  3 03:15:48 2023 : Updating model
Sat Jun  3 03:15:48 2023 : Updating learning rate scheduler
Sat Jun  3 03:15:48 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:15:48 2023 : Run ss scheduler
Sat Jun  3 03:15:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:15:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:15:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:15:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch21_model.tar
Sat Jun  3 03:15:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:15:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:15:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch21_best_val_acc_model.tar
Sat Jun  3 03:15:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch21_best_val_loss_model.tar
Sat Jun  3 03:15:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch21_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
21
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1966.0461103916168
Attempted to log scalar metric secsPerRoundTotal:
210.32838368415833
Sat Jun  3 03:15:53 2023 : ==== iteration 22
Sat Jun  3 03:15:53 2023 : Client learning rate 0.1
Sat Jun  3 03:15:53 2023 : Clients for round 100
Sat Jun  3 03:19:14 2023 : Updating model
Sat Jun  3 03:19:14 2023 : Updating learning rate scheduler
Sat Jun  3 03:19:14 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:19:14 2023 : Run ss scheduler
Sat Jun  3 03:19:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:19:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:19:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:19:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch22_model.tar
Sat Jun  3 03:19:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:19:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:19:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch22_best_val_acc_model.tar
Sat Jun  3 03:19:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch22_best_val_loss_model.tar
Sat Jun  3 03:19:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch22_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
22
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1928.140088558197
Attempted to log scalar metric secsPerRoundTotal:
205.48791766166687
Sat Jun  3 03:19:18 2023 : ==== iteration 23
Sat Jun  3 03:19:18 2023 : Client learning rate 0.1
Sat Jun  3 03:19:18 2023 : Clients for round 100
Sat Jun  3 03:22:15 2023 : Updating model
Sat Jun  3 03:22:15 2023 : Updating learning rate scheduler
Sat Jun  3 03:22:15 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:22:15 2023 : Run ss scheduler
Sat Jun  3 03:22:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:22:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:22:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:22:16 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch23_model.tar
Sat Jun  3 03:22:17 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:22:17 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:22:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch23_best_val_acc_model.tar
Sat Jun  3 03:22:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch23_best_val_loss_model.tar
Sat Jun  3 03:22:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch23_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
23
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1797.7756531238556
Attempted to log scalar metric secsPerRoundTotal:
180.80291318893433
Sat Jun  3 03:22:19 2023 : ==== iteration 24
Sat Jun  3 03:22:19 2023 : Client learning rate 0.1
Sat Jun  3 03:22:19 2023 : Clients for round 100
Sat Jun  3 03:26:22 2023 : Updating model
Sat Jun  3 03:26:22 2023 : Updating learning rate scheduler
Sat Jun  3 03:26:22 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:26:22 2023 : Run ss scheduler
Sat Jun  3 03:26:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:26:23 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:26:23 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:26:23 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch24_model.tar
Sat Jun  3 03:26:24 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:26:24 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:26:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch24_best_val_acc_model.tar
Sat Jun  3 03:26:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch24_best_val_loss_model.tar
Sat Jun  3 03:26:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch24_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
24
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2317.8247373104095
Attempted to log scalar metric secsPerRoundTotal:
247.42804598808289
Sat Jun  3 03:26:27 2023 : ==== iteration 25
Sat Jun  3 03:26:27 2023 : Client learning rate 0.1
Sat Jun  3 03:26:27 2023 : Clients for round 100
Sat Jun  3 03:29:27 2023 : Updating model
Sat Jun  3 03:29:27 2023 : Updating learning rate scheduler
Sat Jun  3 03:29:27 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:29:27 2023 : Run ss scheduler
Sat Jun  3 03:29:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:29:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:29:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:29:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch25_model.tar
Sat Jun  3 03:29:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:29:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:29:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch25_best_val_acc_model.tar
Sat Jun  3 03:29:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch25_best_val_loss_model.tar
Sat Jun  3 03:29:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch25_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
25
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1866.4348530769348
Attempted to log scalar metric secsPerRoundTotal:
185.51824259757996
Sat Jun  3 03:29:32 2023 : ==== iteration 26
Sat Jun  3 03:29:32 2023 : Client learning rate 0.1
Sat Jun  3 03:29:32 2023 : Clients for round 100
Sat Jun  3 03:32:48 2023 : Updating model
Sat Jun  3 03:32:48 2023 : Updating learning rate scheduler
Sat Jun  3 03:32:48 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:32:48 2023 : Run ss scheduler
Sat Jun  3 03:32:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:32:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:32:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:32:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch26_model.tar
Sat Jun  3 03:32:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:32:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:32:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch26_best_val_acc_model.tar
Sat Jun  3 03:32:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch26_best_val_loss_model.tar
Sat Jun  3 03:32:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch26_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
26
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2298.3143508434296
Attempted to log scalar metric secsPerRoundTotal:
200.22354125976562
Sat Jun  3 03:32:52 2023 : ==== iteration 27
Sat Jun  3 03:32:52 2023 : Client learning rate 0.1
Sat Jun  3 03:32:52 2023 : Clients for round 100
Sat Jun  3 03:35:33 2023 : Updating model
Sat Jun  3 03:35:33 2023 : Updating learning rate scheduler
Sat Jun  3 03:35:33 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:35:33 2023 : Run ss scheduler
Sat Jun  3 03:35:33 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:35:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:35:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:35:34 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch27_model.tar
Sat Jun  3 03:35:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:35:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:35:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch27_best_val_acc_model.tar
Sat Jun  3 03:35:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch27_best_val_loss_model.tar
Sat Jun  3 03:35:37 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch27_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
27
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1462.082481622696
Attempted to log scalar metric secsPerRoundTotal:
164.93210220336914
Sat Jun  3 03:35:37 2023 : ==== iteration 28
Sat Jun  3 03:35:37 2023 : Client learning rate 0.1
Sat Jun  3 03:35:37 2023 : Clients for round 100
Sat Jun  3 03:37:48 2023 : Updating model
Sat Jun  3 03:37:48 2023 : Updating learning rate scheduler
Sat Jun  3 03:37:48 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:37:48 2023 : Run ss scheduler
Sat Jun  3 03:37:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:37:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:37:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:37:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch28_model.tar
Sat Jun  3 03:37:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:37:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:37:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch28_best_val_acc_model.tar
Sat Jun  3 03:37:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch28_best_val_loss_model.tar
Sat Jun  3 03:37:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch28_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
28
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1207.9916532039642
Attempted to log scalar metric secsPerRoundTotal:
135.05660033226013
Sat Jun  3 03:37:52 2023 : ==== iteration 29
Sat Jun  3 03:37:52 2023 : Client learning rate 0.1
Sat Jun  3 03:37:52 2023 : Clients for round 100
Sat Jun  3 03:41:06 2023 : Updating model
Sat Jun  3 03:41:06 2023 : Updating learning rate scheduler
Sat Jun  3 03:41:06 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:41:06 2023 : Run ss scheduler
Sat Jun  3 03:41:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:41:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:41:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:41:07 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch29_model.tar
Sat Jun  3 03:41:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:41:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:41:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch29_best_val_acc_model.tar
Sat Jun  3 03:41:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch29_best_val_loss_model.tar
Sat Jun  3 03:41:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch29_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
29
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1787.3239755630493
Attempted to log scalar metric secsPerRoundTotal:
197.53939533233643
Sat Jun  3 03:41:10 2023 : ==== iteration 30
Sat Jun  3 03:41:10 2023 : Client learning rate 0.1
Sat Jun  3 03:41:10 2023 : Clients for round 100
Sat Jun  3 03:45:03 2023 : Updating model
Sat Jun  3 03:45:03 2023 : Updating learning rate scheduler
Sat Jun  3 03:45:03 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:45:03 2023 : Run ss scheduler
Sat Jun  3 03:45:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:45:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:45:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:45:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch30_model.tar
Sat Jun  3 03:45:05 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:45:05 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:45:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch30_best_val_acc_model.tar
Sat Jun  3 03:45:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch30_best_val_loss_model.tar
Sat Jun  3 03:45:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch30_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
30
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2118.430571079254
Attempted to log scalar metric secsPerRoundTotal:
237.47938632965088
Sat Jun  3 03:45:07 2023 : ==== iteration 31
Sat Jun  3 03:45:07 2023 : Client learning rate 0.1
Sat Jun  3 03:45:07 2023 : Clients for round 100
Sat Jun  3 03:48:27 2023 : Updating model
Sat Jun  3 03:48:27 2023 : Updating learning rate scheduler
Sat Jun  3 03:48:27 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:48:27 2023 : Run ss scheduler
Sat Jun  3 03:48:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:48:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:48:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:48:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch31_model.tar
Sat Jun  3 03:48:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:48:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:48:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch31_best_val_acc_model.tar
Sat Jun  3 03:48:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch31_best_val_loss_model.tar
Sat Jun  3 03:48:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch31_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
31
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1907.8475000858307
Attempted to log scalar metric secsPerRoundTotal:
203.67354321479797
Sat Jun  3 03:48:31 2023 : ==== iteration 32
Sat Jun  3 03:48:31 2023 : Client learning rate 0.1
Sat Jun  3 03:48:31 2023 : Clients for round 100
Sat Jun  3 03:51:19 2023 : Updating model
Sat Jun  3 03:51:19 2023 : Updating learning rate scheduler
Sat Jun  3 03:51:19 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:51:19 2023 : Run ss scheduler
Sat Jun  3 03:51:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:51:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:51:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:51:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch32_model.tar
Sat Jun  3 03:51:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:51:21 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:51:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch32_best_val_acc_model.tar
Sat Jun  3 03:51:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch32_best_val_loss_model.tar
Sat Jun  3 03:51:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch32_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
32
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1515.9971814155579
Attempted to log scalar metric secsPerRoundTotal:
171.98069286346436
Sat Jun  3 03:51:23 2023 : ==== iteration 33
Sat Jun  3 03:51:23 2023 : Client learning rate 0.1
Sat Jun  3 03:51:23 2023 : Clients for round 100
Sat Jun  3 03:54:28 2023 : Updating model
Sat Jun  3 03:54:28 2023 : Updating learning rate scheduler
Sat Jun  3 03:54:28 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:54:28 2023 : Run ss scheduler
Sat Jun  3 03:54:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:54:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:54:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:54:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch33_model.tar
Sat Jun  3 03:54:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:54:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:54:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch33_best_val_acc_model.tar
Sat Jun  3 03:54:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch33_best_val_loss_model.tar
Sat Jun  3 03:54:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch33_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
33
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1593.813779592514
Attempted to log scalar metric secsPerRoundTotal:
188.86717677116394
Sat Jun  3 03:54:32 2023 : ==== iteration 34
Sat Jun  3 03:54:32 2023 : Client learning rate 0.1
Sat Jun  3 03:54:32 2023 : Clients for round 100
Sat Jun  3 03:57:41 2023 : Updating model
Sat Jun  3 03:57:41 2023 : Updating learning rate scheduler
Sat Jun  3 03:57:41 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 03:57:41 2023 : Run ss scheduler
Sat Jun  3 03:57:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 03:57:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:57:42 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:57:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch34_model.tar
Sat Jun  3 03:57:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:57:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 03:57:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch34_best_val_acc_model.tar
Sat Jun  3 03:57:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch34_best_val_loss_model.tar
Sat Jun  3 03:57:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch34_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
34
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1722.7246844768524
Attempted to log scalar metric secsPerRoundTotal:
193.33163046836853
Sat Jun  3 03:57:45 2023 : ==== iteration 35
Sat Jun  3 03:57:45 2023 : Client learning rate 0.1
Sat Jun  3 03:57:45 2023 : Clients for round 100
Sat Jun  3 04:00:06 2023 : Updating model
Sat Jun  3 04:00:06 2023 : Updating learning rate scheduler
Sat Jun  3 04:00:06 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:00:06 2023 : Run ss scheduler
Sat Jun  3 04:00:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:00:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:00:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:00:07 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch35_model.tar
Sat Jun  3 04:00:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:00:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:00:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch35_best_val_acc_model.tar
Sat Jun  3 04:00:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch35_best_val_loss_model.tar
Sat Jun  3 04:00:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch35_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
35
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1417.9068775177002
Attempted to log scalar metric secsPerRoundTotal:
145.1543641090393
Sat Jun  3 04:00:10 2023 : ==== iteration 36
Sat Jun  3 04:00:10 2023 : Client learning rate 0.1
Sat Jun  3 04:00:10 2023 : Clients for round 100
Sat Jun  3 04:02:45 2023 : Updating model
Sat Jun  3 04:02:45 2023 : Updating learning rate scheduler
Sat Jun  3 04:02:45 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:02:45 2023 : Run ss scheduler
Sat Jun  3 04:02:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:02:46 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:02:46 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:02:46 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch36_model.tar
Sat Jun  3 04:02:47 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:02:47 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:02:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch36_best_val_acc_model.tar
Sat Jun  3 04:02:49 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch36_best_val_loss_model.tar
Sat Jun  3 04:02:50 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch36_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
36
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1230.1777050495148
Attempted to log scalar metric secsPerRoundTotal:
159.44988083839417
Sat Jun  3 04:02:50 2023 : ==== iteration 37
Sat Jun  3 04:02:50 2023 : Client learning rate 0.1
Sat Jun  3 04:02:50 2023 : Clients for round 100
Sat Jun  3 04:06:50 2023 : Updating model
Sat Jun  3 04:06:50 2023 : Updating learning rate scheduler
Sat Jun  3 04:06:50 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:06:50 2023 : Run ss scheduler
Sat Jun  3 04:06:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:06:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:06:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:06:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch37_model.tar
Sat Jun  3 04:06:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:06:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:06:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch37_best_val_acc_model.tar
Sat Jun  3 04:06:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch37_best_val_loss_model.tar
Sat Jun  3 04:06:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch37_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
37
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1677.394587278366
Attempted to log scalar metric secsPerRoundTotal:
244.96325850486755
Sat Jun  3 04:06:55 2023 : ==== iteration 38
Sat Jun  3 04:06:55 2023 : Client learning rate 0.1
Sat Jun  3 04:06:55 2023 : Clients for round 100
Sat Jun  3 04:10:53 2023 : Updating model
Sat Jun  3 04:10:53 2023 : Updating learning rate scheduler
Sat Jun  3 04:10:53 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:10:53 2023 : Run ss scheduler
Sat Jun  3 04:10:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:10:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:10:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:10:54 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch38_model.tar
Sat Jun  3 04:10:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:10:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:10:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch38_best_val_acc_model.tar
Sat Jun  3 04:10:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch38_best_val_loss_model.tar
Sat Jun  3 04:10:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch38_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
38
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2357.6904628276825
Attempted to log scalar metric secsPerRoundTotal:
243.00248789787292
Sat Jun  3 04:10:58 2023 : ==== iteration 39
Sat Jun  3 04:10:58 2023 : Client learning rate 0.1
Sat Jun  3 04:10:58 2023 : Clients for round 100
Sat Jun  3 04:15:36 2023 : Updating model
Sat Jun  3 04:15:36 2023 : Updating learning rate scheduler
Sat Jun  3 04:15:36 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:15:36 2023 : Run ss scheduler
Sat Jun  3 04:15:36 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:15:37 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:15:37 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:15:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch39_model.tar
Sat Jun  3 04:15:38 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:15:38 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:15:38 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch39_best_val_acc_model.tar
Sat Jun  3 04:15:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch39_best_val_loss_model.tar
Sat Jun  3 04:15:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch39_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
39
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2561.1520795822144
Attempted to log scalar metric secsPerRoundTotal:
282.335000038147
Sat Jun  3 04:15:40 2023 : ==== iteration 40
Sat Jun  3 04:15:40 2023 : Client learning rate 0.1
Sat Jun  3 04:15:40 2023 : Clients for round 100
Sat Jun  3 04:19:55 2023 : Updating model
Sat Jun  3 04:19:55 2023 : Updating learning rate scheduler
Sat Jun  3 04:19:55 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:19:55 2023 : Run ss scheduler
Sat Jun  3 04:19:55 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:19:56 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:19:56 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:19:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch40_model.tar
Sat Jun  3 04:19:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:19:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:19:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch40_best_val_acc_model.tar
Sat Jun  3 04:19:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch40_best_val_loss_model.tar
Sat Jun  3 04:20:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch40_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
40
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2462.9769763946533
Attempted to log scalar metric secsPerRoundTotal:
259.36667466163635
Sat Jun  3 04:20:00 2023 : ==== iteration 41
Sat Jun  3 04:20:00 2023 : Client learning rate 0.1
Sat Jun  3 04:20:00 2023 : Clients for round 100
Sat Jun  3 04:23:12 2023 : Updating model
Sat Jun  3 04:23:12 2023 : Updating learning rate scheduler
Sat Jun  3 04:23:12 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:23:12 2023 : Run ss scheduler
Sat Jun  3 04:23:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:23:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:23:13 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:23:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch41_model.tar
Sat Jun  3 04:23:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:23:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:23:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch41_best_val_acc_model.tar
Sat Jun  3 04:23:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch41_best_val_loss_model.tar
Sat Jun  3 04:23:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch41_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
41
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1443.2720465660095
Attempted to log scalar metric secsPerRoundTotal:
197.28183364868164
Sat Jun  3 04:23:17 2023 : ==== iteration 42
Sat Jun  3 04:23:17 2023 : Client learning rate 0.1
Sat Jun  3 04:23:17 2023 : Clients for round 100
Sat Jun  3 04:27:08 2023 : Updating model
Sat Jun  3 04:27:08 2023 : Updating learning rate scheduler
Sat Jun  3 04:27:08 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:27:08 2023 : Run ss scheduler
Sat Jun  3 04:27:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:27:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:27:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:27:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch42_model.tar
Sat Jun  3 04:27:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:27:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:27:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch42_best_val_acc_model.tar
Sat Jun  3 04:27:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch42_best_val_loss_model.tar
Sat Jun  3 04:27:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch42_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
42
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2111.2367844581604
Attempted to log scalar metric secsPerRoundTotal:
235.17227458953857
Sat Jun  3 04:27:12 2023 : ==== iteration 43
Sat Jun  3 04:27:12 2023 : Client learning rate 0.1
Sat Jun  3 04:27:12 2023 : Clients for round 100
Sat Jun  3 04:31:02 2023 : Updating model
Sat Jun  3 04:31:02 2023 : Updating learning rate scheduler
Sat Jun  3 04:31:02 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:31:02 2023 : Run ss scheduler
Sat Jun  3 04:31:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:31:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:31:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:31:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch43_model.tar
Sat Jun  3 04:31:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:31:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:31:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch43_best_val_acc_model.tar
Sat Jun  3 04:31:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch43_best_val_loss_model.tar
Sat Jun  3 04:31:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch43_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
43
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1746.1527626514435
Attempted to log scalar metric secsPerRoundTotal:
235.00056624412537
Sat Jun  3 04:31:07 2023 : ==== iteration 44
Sat Jun  3 04:31:07 2023 : Client learning rate 0.1
Sat Jun  3 04:31:07 2023 : Clients for round 100
Sat Jun  3 04:34:48 2023 : Updating model
Sat Jun  3 04:34:48 2023 : Updating learning rate scheduler
Sat Jun  3 04:34:48 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:34:48 2023 : Run ss scheduler
Sat Jun  3 04:34:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:34:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:34:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:34:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch44_model.tar
Sat Jun  3 04:34:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:34:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:34:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch44_best_val_acc_model.tar
Sat Jun  3 04:34:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch44_best_val_loss_model.tar
Sat Jun  3 04:34:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch44_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
44
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1784.0099427700043
Attempted to log scalar metric secsPerRoundTotal:
226.2034215927124
Sat Jun  3 04:34:53 2023 : ==== iteration 45
Sat Jun  3 04:34:53 2023 : Client learning rate 0.1
Sat Jun  3 04:34:53 2023 : Clients for round 100
Sat Jun  3 04:38:17 2023 : Updating model
Sat Jun  3 04:38:17 2023 : Updating learning rate scheduler
Sat Jun  3 04:38:17 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:38:17 2023 : Run ss scheduler
Sat Jun  3 04:38:17 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:38:18 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:38:18 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:38:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch45_model.tar
Sat Jun  3 04:38:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:38:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:38:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch45_best_val_acc_model.tar
Sat Jun  3 04:38:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch45_best_val_loss_model.tar
Sat Jun  3 04:38:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch45_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
45
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1961.952425956726
Attempted to log scalar metric secsPerRoundTotal:
208.61087918281555
Sat Jun  3 04:38:22 2023 : ==== iteration 46
Sat Jun  3 04:38:22 2023 : Client learning rate 0.1
Sat Jun  3 04:38:22 2023 : Clients for round 100
Sat Jun  3 04:40:18 2023 : Updating model
Sat Jun  3 04:40:18 2023 : Updating learning rate scheduler
Sat Jun  3 04:40:18 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:40:18 2023 : Run ss scheduler
Sat Jun  3 04:40:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:40:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:40:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:40:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch46_model.tar
Sat Jun  3 04:40:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:40:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:40:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch46_best_val_acc_model.tar
Sat Jun  3 04:40:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch46_best_val_loss_model.tar
Sat Jun  3 04:40:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch46_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
46
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1206.666156411171
Attempted to log scalar metric secsPerRoundTotal:
120.72421646118164
Sat Jun  3 04:40:22 2023 : ==== iteration 47
Sat Jun  3 04:40:22 2023 : Client learning rate 0.1
Sat Jun  3 04:40:23 2023 : Clients for round 100
Sat Jun  3 04:44:09 2023 : Updating model
Sat Jun  3 04:44:09 2023 : Updating learning rate scheduler
Sat Jun  3 04:44:09 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:44:09 2023 : Run ss scheduler
Sat Jun  3 04:44:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:44:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:44:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:44:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch47_model.tar
Sat Jun  3 04:44:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:44:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:44:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch47_best_val_acc_model.tar
Sat Jun  3 04:44:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch47_best_val_loss_model.tar
Sat Jun  3 04:44:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch47_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
47
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2015.171168088913
Attempted to log scalar metric secsPerRoundTotal:
231.1659164428711
Sat Jun  3 04:44:14 2023 : ==== iteration 48
Sat Jun  3 04:44:14 2023 : Client learning rate 0.1
Sat Jun  3 04:44:14 2023 : Clients for round 100
Sat Jun  3 04:47:17 2023 : Updating model
Sat Jun  3 04:47:17 2023 : Updating learning rate scheduler
Sat Jun  3 04:47:17 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:47:17 2023 : Run ss scheduler
Sat Jun  3 04:47:17 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:47:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:47:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:47:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch48_model.tar
Sat Jun  3 04:47:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:47:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:47:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch48_best_val_acc_model.tar
Sat Jun  3 04:47:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch48_best_val_loss_model.tar
Sat Jun  3 04:47:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch48_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
48
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1550.244408607483
Attempted to log scalar metric secsPerRoundTotal:
188.16976189613342
Sat Jun  3 04:47:22 2023 : ==== iteration 49
Sat Jun  3 04:47:22 2023 : Client learning rate 0.1
Sat Jun  3 04:47:22 2023 : Clients for round 100
Sat Jun  3 04:50:42 2023 : Updating model
Sat Jun  3 04:50:42 2023 : Updating learning rate scheduler
Sat Jun  3 04:50:42 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:50:42 2023 : Run ss scheduler
Sat Jun  3 04:50:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:50:43 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:50:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:50:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch49_model.tar
Sat Jun  3 04:50:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:50:44 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:50:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch49_best_val_acc_model.tar
Sat Jun  3 04:50:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch49_best_val_loss_model.tar
Sat Jun  3 04:50:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch49_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
49
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1601.1994671821594
Attempted to log scalar metric secsPerRoundTotal:
204.95824241638184
Sat Jun  3 04:50:47 2023 : ==== iteration 50
Sat Jun  3 04:50:47 2023 : Client learning rate 0.1
Sat Jun  3 04:50:47 2023 : Clients for round 100
Sat Jun  3 04:53:14 2023 : Updating model
Sat Jun  3 04:53:14 2023 : Updating learning rate scheduler
Sat Jun  3 04:53:14 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:53:14 2023 : Run ss scheduler
Sat Jun  3 04:53:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:53:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:53:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:53:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch50_model.tar
Sat Jun  3 04:53:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:53:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:53:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch50_best_val_acc_model.tar
Sat Jun  3 04:53:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch50_best_val_loss_model.tar
Sat Jun  3 04:53:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch50_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
50
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1337.2435719966888
Attempted to log scalar metric secsPerRoundTotal:
151.73853969573975
Sat Jun  3 04:53:19 2023 : ==== iteration 51
Sat Jun  3 04:53:19 2023 : Client learning rate 0.1
Sat Jun  3 04:53:19 2023 : Clients for round 100
Sat Jun  3 04:56:58 2023 : Updating model
Sat Jun  3 04:56:58 2023 : Updating learning rate scheduler
Sat Jun  3 04:56:58 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:56:58 2023 : Run ss scheduler
Sat Jun  3 04:56:58 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:56:59 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:56:59 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:56:59 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch51_model.tar
Sat Jun  3 04:57:00 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:57:00 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:57:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch51_best_val_acc_model.tar
Sat Jun  3 04:57:01 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch51_best_val_loss_model.tar
Sat Jun  3 04:57:02 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch51_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
51
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2080.2390711307526
Attempted to log scalar metric secsPerRoundTotal:
223.60989809036255
Sat Jun  3 04:57:02 2023 : ==== iteration 52
Sat Jun  3 04:57:02 2023 : Client learning rate 0.1
Sat Jun  3 04:57:02 2023 : Clients for round 100
Sat Jun  3 04:59:52 2023 : Updating model
Sat Jun  3 04:59:52 2023 : Updating learning rate scheduler
Sat Jun  3 04:59:52 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 04:59:52 2023 : Run ss scheduler
Sat Jun  3 04:59:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 04:59:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:59:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:59:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch52_model.tar
Sat Jun  3 04:59:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:59:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 04:59:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch52_best_val_acc_model.tar
Sat Jun  3 04:59:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch52_best_val_loss_model.tar
Sat Jun  3 04:59:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch52_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
52
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1437.8683819770813
Attempted to log scalar metric secsPerRoundTotal:
174.52396440505981
Sat Jun  3 04:59:57 2023 : ==== iteration 53
Sat Jun  3 04:59:57 2023 : Client learning rate 0.1
Sat Jun  3 04:59:57 2023 : Clients for round 100
Sat Jun  3 05:02:49 2023 : Updating model
Sat Jun  3 05:02:49 2023 : Updating learning rate scheduler
Sat Jun  3 05:02:49 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:02:49 2023 : Run ss scheduler
Sat Jun  3 05:02:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:02:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:02:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:02:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch53_model.tar
Sat Jun  3 05:02:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:02:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:02:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch53_best_val_acc_model.tar
Sat Jun  3 05:02:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch53_best_val_loss_model.tar
Sat Jun  3 05:02:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch53_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
53
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1714.974331855774
Attempted to log scalar metric secsPerRoundTotal:
177.53096628189087
Sat Jun  3 05:02:54 2023 : ==== iteration 54
Sat Jun  3 05:02:54 2023 : Client learning rate 0.1
Sat Jun  3 05:02:54 2023 : Clients for round 100
Sat Jun  3 05:05:29 2023 : Updating model
Sat Jun  3 05:05:29 2023 : Updating learning rate scheduler
Sat Jun  3 05:05:29 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:05:29 2023 : Run ss scheduler
Sat Jun  3 05:05:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:05:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:05:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:05:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch54_model.tar
Sat Jun  3 05:05:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:05:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:05:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch54_best_val_acc_model.tar
Sat Jun  3 05:05:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch54_best_val_loss_model.tar
Sat Jun  3 05:05:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch54_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
54
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1427.65860247612
Attempted to log scalar metric secsPerRoundTotal:
159.5940821170807
Sat Jun  3 05:05:34 2023 : ==== iteration 55
Sat Jun  3 05:05:34 2023 : Client learning rate 0.1
Sat Jun  3 05:05:34 2023 : Clients for round 100
Sat Jun  3 05:08:00 2023 : Updating model
Sat Jun  3 05:08:00 2023 : Updating learning rate scheduler
Sat Jun  3 05:08:00 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:08:00 2023 : Run ss scheduler
Sat Jun  3 05:08:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:08:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:08:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:08:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch55_model.tar
Sat Jun  3 05:08:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:08:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:08:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch55_best_val_acc_model.tar
Sat Jun  3 05:08:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch55_best_val_loss_model.tar
Sat Jun  3 05:08:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch55_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
55
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1536.5647888183594
Attempted to log scalar metric secsPerRoundTotal:
151.00584173202515
Sat Jun  3 05:08:05 2023 : ==== iteration 56
Sat Jun  3 05:08:05 2023 : Client learning rate 0.1
Sat Jun  3 05:08:05 2023 : Clients for round 100
Sat Jun  3 05:11:33 2023 : Updating model
Sat Jun  3 05:11:33 2023 : Updating learning rate scheduler
Sat Jun  3 05:11:33 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:11:33 2023 : Run ss scheduler
Sat Jun  3 05:11:33 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:11:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:11:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:11:34 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch56_model.tar
Sat Jun  3 05:11:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:11:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:11:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch56_best_val_acc_model.tar
Sat Jun  3 05:11:37 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch56_best_val_loss_model.tar
Sat Jun  3 05:11:37 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch56_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
56
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1794.3000527620316
Attempted to log scalar metric secsPerRoundTotal:
212.4214324951172
Sat Jun  3 05:11:37 2023 : ==== iteration 57
Sat Jun  3 05:11:37 2023 : Client learning rate 0.1
Sat Jun  3 05:11:37 2023 : Clients for round 100
Sat Jun  3 05:15:02 2023 : Updating model
Sat Jun  3 05:15:02 2023 : Updating learning rate scheduler
Sat Jun  3 05:15:02 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:15:02 2023 : Run ss scheduler
Sat Jun  3 05:15:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:15:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:15:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:15:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch57_model.tar
Sat Jun  3 05:15:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:15:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:15:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch57_best_val_acc_model.tar
Sat Jun  3 05:15:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch57_best_val_loss_model.tar
Sat Jun  3 05:15:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch57_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
57
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1696.9727087020874
Attempted to log scalar metric secsPerRoundTotal:
209.27263188362122
Sat Jun  3 05:15:06 2023 : ==== iteration 58
Sat Jun  3 05:15:06 2023 : Client learning rate 0.1
Sat Jun  3 05:15:07 2023 : Clients for round 100
Sat Jun  3 05:18:00 2023 : Updating model
Sat Jun  3 05:18:00 2023 : Updating learning rate scheduler
Sat Jun  3 05:18:00 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:18:00 2023 : Run ss scheduler
Sat Jun  3 05:18:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:18:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:18:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:18:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch58_model.tar
Sat Jun  3 05:18:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:18:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:18:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch58_best_val_acc_model.tar
Sat Jun  3 05:18:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch58_best_val_loss_model.tar
Sat Jun  3 05:18:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch58_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
58
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1500.1700472831726
Attempted to log scalar metric secsPerRoundTotal:
178.07302904129028
Sat Jun  3 05:18:05 2023 : ==== iteration 59
Sat Jun  3 05:18:05 2023 : Client learning rate 0.1
Sat Jun  3 05:18:05 2023 : Clients for round 100
Sat Jun  3 05:21:01 2023 : Updating model
Sat Jun  3 05:21:01 2023 : Updating learning rate scheduler
Sat Jun  3 05:21:01 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:21:01 2023 : Run ss scheduler
Sat Jun  3 05:21:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:21:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:21:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:21:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch59_model.tar
Sat Jun  3 05:21:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:21:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:21:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch59_best_val_acc_model.tar
Sat Jun  3 05:21:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch59_best_val_loss_model.tar
Sat Jun  3 05:21:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch59_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
59
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1588.5370779037476
Attempted to log scalar metric secsPerRoundTotal:
181.1686873435974
Sat Jun  3 05:21:06 2023 : ==== iteration 60
Sat Jun  3 05:21:06 2023 : Client learning rate 0.1
Sat Jun  3 05:21:06 2023 : Clients for round 100
Sat Jun  3 05:23:59 2023 : Updating model
Sat Jun  3 05:23:59 2023 : Updating learning rate scheduler
Sat Jun  3 05:23:59 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:23:59 2023 : Run ss scheduler
Sat Jun  3 05:23:59 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:24:00 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:24:00 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:24:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch60_model.tar
Sat Jun  3 05:24:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:24:01 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:24:02 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch60_best_val_acc_model.tar
Sat Jun  3 05:24:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch60_best_val_loss_model.tar
Sat Jun  3 05:24:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch60_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
60
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1279.048271536827
Attempted to log scalar metric secsPerRoundTotal:
177.91827630996704
Sat Jun  3 05:24:04 2023 : ==== iteration 61
Sat Jun  3 05:24:04 2023 : Client learning rate 0.1
Sat Jun  3 05:24:04 2023 : Clients for round 100
Sat Jun  3 05:27:06 2023 : Updating model
Sat Jun  3 05:27:06 2023 : Updating learning rate scheduler
Sat Jun  3 05:27:06 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:27:06 2023 : Run ss scheduler
Sat Jun  3 05:27:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:27:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:27:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:27:07 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch61_model.tar
Sat Jun  3 05:27:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:27:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:27:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch61_best_val_acc_model.tar
Sat Jun  3 05:27:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch61_best_val_loss_model.tar
Sat Jun  3 05:27:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch61_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
61
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1482.7579565048218
Attempted to log scalar metric secsPerRoundTotal:
186.82091331481934
Sat Jun  3 05:27:10 2023 : ==== iteration 62
Sat Jun  3 05:27:10 2023 : Client learning rate 0.1
Sat Jun  3 05:27:10 2023 : Clients for round 100
Sat Jun  3 05:30:49 2023 : Updating model
Sat Jun  3 05:30:49 2023 : Updating learning rate scheduler
Sat Jun  3 05:30:49 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:30:49 2023 : Run ss scheduler
Sat Jun  3 05:30:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:30:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:30:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:30:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch62_model.tar
Sat Jun  3 05:30:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:30:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:30:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch62_best_val_acc_model.tar
Sat Jun  3 05:30:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch62_best_val_loss_model.tar
Sat Jun  3 05:30:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch62_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
62
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2004.389896273613
Attempted to log scalar metric secsPerRoundTotal:
223.63607692718506
Sat Jun  3 05:30:54 2023 : ==== iteration 63
Sat Jun  3 05:30:54 2023 : Client learning rate 0.1
Sat Jun  3 05:30:54 2023 : Clients for round 100
Sat Jun  3 05:33:08 2023 : Updating model
Sat Jun  3 05:33:08 2023 : Updating learning rate scheduler
Sat Jun  3 05:33:08 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:33:08 2023 : Run ss scheduler
Sat Jun  3 05:33:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:33:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:33:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:33:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch63_model.tar
Sat Jun  3 05:33:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:33:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:33:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch63_best_val_acc_model.tar
Sat Jun  3 05:33:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch63_best_val_loss_model.tar
Sat Jun  3 05:33:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch63_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
63
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1199.2649154663086
Attempted to log scalar metric secsPerRoundTotal:
138.19515681266785
Sat Jun  3 05:33:12 2023 : ==== iteration 64
Sat Jun  3 05:33:12 2023 : Client learning rate 0.1
Sat Jun  3 05:33:12 2023 : Clients for round 100
Sat Jun  3 05:36:13 2023 : Updating model
Sat Jun  3 05:36:13 2023 : Updating learning rate scheduler
Sat Jun  3 05:36:13 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:36:13 2023 : Run ss scheduler
Sat Jun  3 05:36:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:36:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:36:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:36:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch64_model.tar
Sat Jun  3 05:36:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:36:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:36:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch64_best_val_acc_model.tar
Sat Jun  3 05:36:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch64_best_val_loss_model.tar
Sat Jun  3 05:36:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch64_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
64
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1832.973994731903
Attempted to log scalar metric secsPerRoundTotal:
184.5904152393341
Sat Jun  3 05:36:17 2023 : ==== iteration 65
Sat Jun  3 05:36:17 2023 : Client learning rate 0.1
Sat Jun  3 05:36:17 2023 : Clients for round 100
Sat Jun  3 05:39:21 2023 : Updating model
Sat Jun  3 05:39:21 2023 : Updating learning rate scheduler
Sat Jun  3 05:39:21 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:39:21 2023 : Run ss scheduler
Sat Jun  3 05:39:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:39:22 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:39:22 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:39:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch65_model.tar
Sat Jun  3 05:39:23 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:39:23 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:39:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch65_best_val_acc_model.tar
Sat Jun  3 05:39:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch65_best_val_loss_model.tar
Sat Jun  3 05:39:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch65_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
65
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1643.5280947685242
Attempted to log scalar metric secsPerRoundTotal:
188.22108387947083
Sat Jun  3 05:39:25 2023 : ==== iteration 66
Sat Jun  3 05:39:25 2023 : Client learning rate 0.1
Sat Jun  3 05:39:25 2023 : Clients for round 100
Sat Jun  3 05:42:06 2023 : Updating model
Sat Jun  3 05:42:06 2023 : Updating learning rate scheduler
Sat Jun  3 05:42:06 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:42:06 2023 : Run ss scheduler
Sat Jun  3 05:42:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:42:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:42:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:42:07 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch66_model.tar
Sat Jun  3 05:42:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:42:08 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:42:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch66_best_val_acc_model.tar
Sat Jun  3 05:42:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch66_best_val_loss_model.tar
Sat Jun  3 05:42:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch66_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
66
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1305.692715883255
Attempted to log scalar metric secsPerRoundTotal:
165.73758721351624
Sat Jun  3 05:42:11 2023 : ==== iteration 67
Sat Jun  3 05:42:11 2023 : Client learning rate 0.1
Sat Jun  3 05:42:11 2023 : Clients for round 100
Sat Jun  3 05:45:13 2023 : Updating model
Sat Jun  3 05:45:13 2023 : Updating learning rate scheduler
Sat Jun  3 05:45:13 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:45:13 2023 : Run ss scheduler
Sat Jun  3 05:45:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:45:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:45:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:45:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch67_model.tar
Sat Jun  3 05:45:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:45:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:45:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch67_best_val_acc_model.tar
Sat Jun  3 05:45:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch67_best_val_loss_model.tar
Sat Jun  3 05:45:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch67_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
67
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1925.9776287078857
Attempted to log scalar metric secsPerRoundTotal:
186.3124496936798
Sat Jun  3 05:45:17 2023 : ==== iteration 68
Sat Jun  3 05:45:17 2023 : Client learning rate 0.1
Sat Jun  3 05:45:17 2023 : Clients for round 100
Sat Jun  3 05:48:28 2023 : Updating model
Sat Jun  3 05:48:28 2023 : Updating learning rate scheduler
Sat Jun  3 05:48:28 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:48:28 2023 : Run ss scheduler
Sat Jun  3 05:48:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:48:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:48:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:48:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch68_model.tar
Sat Jun  3 05:48:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:48:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:48:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch68_best_val_acc_model.tar
Sat Jun  3 05:48:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch68_best_val_loss_model.tar
Sat Jun  3 05:48:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch68_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
68
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1626.5235707759857
Attempted to log scalar metric secsPerRoundTotal:
195.66842079162598
Sat Jun  3 05:48:33 2023 : ==== iteration 69
Sat Jun  3 05:48:33 2023 : Client learning rate 0.1
Sat Jun  3 05:48:33 2023 : Clients for round 100
Sat Jun  3 05:51:53 2023 : Updating model
Sat Jun  3 05:51:53 2023 : Updating learning rate scheduler
Sat Jun  3 05:51:53 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:51:53 2023 : Run ss scheduler
Sat Jun  3 05:51:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:51:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:51:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:51:54 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch69_model.tar
Sat Jun  3 05:51:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:51:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:51:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch69_best_val_acc_model.tar
Sat Jun  3 05:51:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch69_best_val_loss_model.tar
Sat Jun  3 05:51:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch69_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
69
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1774.4534752368927
Attempted to log scalar metric secsPerRoundTotal:
204.39896893501282
Sat Jun  3 05:51:57 2023 : ==== iteration 70
Sat Jun  3 05:51:57 2023 : Client learning rate 0.1
Sat Jun  3 05:51:57 2023 : Clients for round 100
Sat Jun  3 05:56:08 2023 : Updating model
Sat Jun  3 05:56:08 2023 : Updating learning rate scheduler
Sat Jun  3 05:56:08 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:56:08 2023 : Run ss scheduler
Sat Jun  3 05:56:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:56:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:56:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:56:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch70_model.tar
Sat Jun  3 05:56:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:56:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:56:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch70_best_val_acc_model.tar
Sat Jun  3 05:56:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch70_best_val_loss_model.tar
Sat Jun  3 05:56:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch70_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
70
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2545.5547227859497
Attempted to log scalar metric secsPerRoundTotal:
255.37011790275574
Sat Jun  3 05:56:13 2023 : ==== iteration 71
Sat Jun  3 05:56:13 2023 : Client learning rate 0.1
Sat Jun  3 05:56:13 2023 : Clients for round 100
Sat Jun  3 05:59:02 2023 : Updating model
Sat Jun  3 05:59:02 2023 : Updating learning rate scheduler
Sat Jun  3 05:59:02 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 05:59:02 2023 : Run ss scheduler
Sat Jun  3 05:59:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 05:59:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:59:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:59:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch71_model.tar
Sat Jun  3 05:59:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:59:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 05:59:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch71_best_val_acc_model.tar
Sat Jun  3 05:59:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch71_best_val_loss_model.tar
Sat Jun  3 05:59:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch71_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
71
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1531.3226253986359
Attempted to log scalar metric secsPerRoundTotal:
173.9564094543457
Sat Jun  3 05:59:07 2023 : ==== iteration 72
Sat Jun  3 05:59:07 2023 : Client learning rate 0.1
Sat Jun  3 05:59:07 2023 : Clients for round 100
Sat Jun  3 06:01:54 2023 : Updating model
Sat Jun  3 06:01:54 2023 : Updating learning rate scheduler
Sat Jun  3 06:01:54 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:01:54 2023 : Run ss scheduler
Sat Jun  3 06:01:54 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:01:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:01:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:01:55 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch72_model.tar
Sat Jun  3 06:01:56 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:01:56 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:01:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch72_best_val_acc_model.tar
Sat Jun  3 06:01:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch72_best_val_loss_model.tar
Sat Jun  3 06:01:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch72_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
72
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1792.6959600448608
Attempted to log scalar metric secsPerRoundTotal:
172.04129338264465
Sat Jun  3 06:01:59 2023 : ==== iteration 73
Sat Jun  3 06:01:59 2023 : Client learning rate 0.1
Sat Jun  3 06:01:59 2023 : Clients for round 100
Sat Jun  3 06:04:08 2023 : Updating model
Sat Jun  3 06:04:08 2023 : Updating learning rate scheduler
Sat Jun  3 06:04:08 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:04:08 2023 : Run ss scheduler
Sat Jun  3 06:04:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:04:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:04:09 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:04:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch73_model.tar
Sat Jun  3 06:04:10 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:04:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:04:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch73_best_val_acc_model.tar
Sat Jun  3 06:04:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch73_best_val_loss_model.tar
Sat Jun  3 06:04:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch73_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
73
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1192.5822645425797
Attempted to log scalar metric secsPerRoundTotal:
134.41896414756775
Sat Jun  3 06:04:13 2023 : ==== iteration 74
Sat Jun  3 06:04:13 2023 : Client learning rate 0.1
Sat Jun  3 06:04:13 2023 : Clients for round 100
Sat Jun  3 06:07:31 2023 : Updating model
Sat Jun  3 06:07:31 2023 : Updating learning rate scheduler
Sat Jun  3 06:07:31 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:07:31 2023 : Run ss scheduler
Sat Jun  3 06:07:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:07:32 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:07:32 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:07:32 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch74_model.tar
Sat Jun  3 06:07:33 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:07:33 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:07:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch74_best_val_acc_model.tar
Sat Jun  3 06:07:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch74_best_val_loss_model.tar
Sat Jun  3 06:07:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch74_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
74
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1545.3146064281464
Attempted to log scalar metric secsPerRoundTotal:
201.76552152633667
Sat Jun  3 06:07:35 2023 : ==== iteration 75
Sat Jun  3 06:07:35 2023 : Client learning rate 0.1
Sat Jun  3 06:07:35 2023 : Clients for round 100
Sat Jun  3 06:11:15 2023 : Updating model
Sat Jun  3 06:11:15 2023 : Updating learning rate scheduler
Sat Jun  3 06:11:15 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:11:15 2023 : Run ss scheduler
Sat Jun  3 06:11:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:11:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:11:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:11:16 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch75_model.tar
Sat Jun  3 06:11:17 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:11:17 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:11:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch75_best_val_acc_model.tar
Sat Jun  3 06:11:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch75_best_val_loss_model.tar
Sat Jun  3 06:11:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch75_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
75
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1767.1400904655457
Attempted to log scalar metric secsPerRoundTotal:
224.49336624145508
Sat Jun  3 06:11:19 2023 : ==== iteration 76
Sat Jun  3 06:11:19 2023 : Client learning rate 0.1
Sat Jun  3 06:11:19 2023 : Clients for round 100
Sat Jun  3 06:14:49 2023 : Updating model
Sat Jun  3 06:14:49 2023 : Updating learning rate scheduler
Sat Jun  3 06:14:49 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:14:49 2023 : Run ss scheduler
Sat Jun  3 06:14:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:14:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:14:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:14:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch76_model.tar
Sat Jun  3 06:14:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:14:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:14:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch76_best_val_acc_model.tar
Sat Jun  3 06:14:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch76_best_val_loss_model.tar
Sat Jun  3 06:14:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch76_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
76
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1928.8878676891327
Attempted to log scalar metric secsPerRoundTotal:
214.31265473365784
Sat Jun  3 06:14:54 2023 : ==== iteration 77
Sat Jun  3 06:14:54 2023 : Client learning rate 0.1
Sat Jun  3 06:14:54 2023 : Clients for round 100
Sat Jun  3 06:17:25 2023 : Updating model
Sat Jun  3 06:17:25 2023 : Updating learning rate scheduler
Sat Jun  3 06:17:25 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:17:25 2023 : Run ss scheduler
Sat Jun  3 06:17:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:17:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:17:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:17:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch77_model.tar
Sat Jun  3 06:17:27 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:17:27 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:17:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch77_best_val_acc_model.tar
Sat Jun  3 06:17:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch77_best_val_loss_model.tar
Sat Jun  3 06:17:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch77_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
77
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1285.8237923383713
Attempted to log scalar metric secsPerRoundTotal:
155.85355496406555
Sat Jun  3 06:17:29 2023 : ==== iteration 78
Sat Jun  3 06:17:29 2023 : Client learning rate 0.1
Sat Jun  3 06:17:29 2023 : Clients for round 100
Sat Jun  3 06:20:50 2023 : Updating model
Sat Jun  3 06:20:50 2023 : Updating learning rate scheduler
Sat Jun  3 06:20:50 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:20:50 2023 : Run ss scheduler
Sat Jun  3 06:20:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:20:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:20:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:20:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch78_model.tar
Sat Jun  3 06:20:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:20:52 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:20:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch78_best_val_acc_model.tar
Sat Jun  3 06:20:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch78_best_val_loss_model.tar
Sat Jun  3 06:20:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch78_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
78
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1688.733800649643
Attempted to log scalar metric secsPerRoundTotal:
205.6237850189209
Sat Jun  3 06:20:55 2023 : ==== iteration 79
Sat Jun  3 06:20:55 2023 : Client learning rate 0.1
Sat Jun  3 06:20:55 2023 : Clients for round 100
Sat Jun  3 06:25:27 2023 : Updating model
Sat Jun  3 06:25:27 2023 : Updating learning rate scheduler
Sat Jun  3 06:25:27 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:25:27 2023 : Run ss scheduler
Sat Jun  3 06:25:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:25:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:25:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:25:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch79_model.tar
Sat Jun  3 06:25:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:25:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:25:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch79_best_val_acc_model.tar
Sat Jun  3 06:25:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch79_best_val_loss_model.tar
Sat Jun  3 06:25:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch79_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
79
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2161.6611493825912
Attempted to log scalar metric secsPerRoundTotal:
276.27840638160706
Sat Jun  3 06:25:31 2023 : ==== iteration 80
Sat Jun  3 06:25:31 2023 : Client learning rate 0.1
Sat Jun  3 06:25:31 2023 : Clients for round 100
Sat Jun  3 06:29:29 2023 : Updating model
Sat Jun  3 06:29:29 2023 : Updating learning rate scheduler
Sat Jun  3 06:29:29 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:29:29 2023 : Run ss scheduler
Sat Jun  3 06:29:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:29:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:29:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:29:30 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch80_model.tar
Sat Jun  3 06:29:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:29:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:29:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch80_best_val_acc_model.tar
Sat Jun  3 06:29:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch80_best_val_loss_model.tar
Sat Jun  3 06:29:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch80_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
80
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2271.169945716858
Attempted to log scalar metric secsPerRoundTotal:
241.93819165229797
Sat Jun  3 06:29:33 2023 : ==== iteration 81
Sat Jun  3 06:29:33 2023 : Client learning rate 0.1
Sat Jun  3 06:29:33 2023 : Clients for round 100
Sat Jun  3 06:32:14 2023 : Updating model
Sat Jun  3 06:32:14 2023 : Updating learning rate scheduler
Sat Jun  3 06:32:14 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:32:14 2023 : Run ss scheduler
Sat Jun  3 06:32:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:32:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:32:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:32:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch81_model.tar
Sat Jun  3 06:32:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:32:16 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:32:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch81_best_val_acc_model.tar
Sat Jun  3 06:32:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch81_best_val_loss_model.tar
Sat Jun  3 06:32:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch81_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
81
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1405.4776598215103
Attempted to log scalar metric secsPerRoundTotal:
165.18449783325195
Sat Jun  3 06:32:18 2023 : ==== iteration 82
Sat Jun  3 06:32:18 2023 : Client learning rate 0.1
Sat Jun  3 06:32:18 2023 : Clients for round 100
Sat Jun  3 06:35:18 2023 : Updating model
Sat Jun  3 06:35:18 2023 : Updating learning rate scheduler
Sat Jun  3 06:35:18 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:35:18 2023 : Run ss scheduler
Sat Jun  3 06:35:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:35:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:35:19 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:35:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch82_model.tar
Sat Jun  3 06:35:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:35:20 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:35:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch82_best_val_acc_model.tar
Sat Jun  3 06:35:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch82_best_val_loss_model.tar
Sat Jun  3 06:35:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch82_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
82
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1504.6016569137573
Attempted to log scalar metric secsPerRoundTotal:
183.78804993629456
Sat Jun  3 06:35:22 2023 : ==== iteration 83
Sat Jun  3 06:35:22 2023 : Client learning rate 0.1
Sat Jun  3 06:35:22 2023 : Clients for round 100
Sat Jun  3 06:38:02 2023 : Updating model
Sat Jun  3 06:38:02 2023 : Updating learning rate scheduler
Sat Jun  3 06:38:02 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:38:02 2023 : Run ss scheduler
Sat Jun  3 06:38:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:38:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:38:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:38:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch83_model.tar
Sat Jun  3 06:38:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:38:04 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:38:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch83_best_val_acc_model.tar
Sat Jun  3 06:38:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch83_best_val_loss_model.tar
Sat Jun  3 06:38:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch83_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
83
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1131.910508275032
Attempted to log scalar metric secsPerRoundTotal:
164.44287085533142
Sat Jun  3 06:38:07 2023 : ==== iteration 84
Sat Jun  3 06:38:07 2023 : Client learning rate 0.1
Sat Jun  3 06:38:07 2023 : Clients for round 100
Sat Jun  3 06:41:24 2023 : Updating model
Sat Jun  3 06:41:24 2023 : Updating learning rate scheduler
Sat Jun  3 06:41:24 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:41:24 2023 : Run ss scheduler
Sat Jun  3 06:41:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:41:25 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:41:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:41:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch84_model.tar
Sat Jun  3 06:41:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:41:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:41:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch84_best_val_acc_model.tar
Sat Jun  3 06:41:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch84_best_val_loss_model.tar
Sat Jun  3 06:41:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch84_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
84
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1620.320741057396
Attempted to log scalar metric secsPerRoundTotal:
202.4329264163971
Sat Jun  3 06:41:29 2023 : ==== iteration 85
Sat Jun  3 06:41:29 2023 : Client learning rate 0.1
Sat Jun  3 06:41:29 2023 : Clients for round 100
Sat Jun  3 06:44:01 2023 : Updating model
Sat Jun  3 06:44:01 2023 : Updating learning rate scheduler
Sat Jun  3 06:44:01 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:44:01 2023 : Run ss scheduler
Sat Jun  3 06:44:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:44:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:44:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:44:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch85_model.tar
Sat Jun  3 06:44:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:44:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:44:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch85_best_val_acc_model.tar
Sat Jun  3 06:44:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch85_best_val_loss_model.tar
Sat Jun  3 06:44:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch85_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
85
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1314.960381269455
Attempted to log scalar metric secsPerRoundTotal:
157.10350823402405
Sat Jun  3 06:44:06 2023 : ==== iteration 86
Sat Jun  3 06:44:06 2023 : Client learning rate 0.1
Sat Jun  3 06:44:06 2023 : Clients for round 100
Sat Jun  3 06:48:53 2023 : Updating model
Sat Jun  3 06:48:53 2023 : Updating learning rate scheduler
Sat Jun  3 06:48:53 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:48:53 2023 : Run ss scheduler
Sat Jun  3 06:48:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:48:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:48:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:48:54 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch86_model.tar
Sat Jun  3 06:48:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:48:55 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:48:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch86_best_val_acc_model.tar
Sat Jun  3 06:48:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch86_best_val_loss_model.tar
Sat Jun  3 06:48:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch86_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
86
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2343.800940513611
Attempted to log scalar metric secsPerRoundTotal:
291.55714988708496
Sat Jun  3 06:48:58 2023 : ==== iteration 87
Sat Jun  3 06:48:58 2023 : Client learning rate 0.1
Sat Jun  3 06:48:58 2023 : Clients for round 100
Sat Jun  3 06:52:05 2023 : Updating model
Sat Jun  3 06:52:05 2023 : Updating learning rate scheduler
Sat Jun  3 06:52:05 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:52:05 2023 : Run ss scheduler
Sat Jun  3 06:52:05 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:52:06 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:52:06 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:52:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch87_model.tar
Sat Jun  3 06:52:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:52:07 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:52:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch87_best_val_acc_model.tar
Sat Jun  3 06:52:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch87_best_val_loss_model.tar
Sat Jun  3 06:52:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch87_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
87
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1384.923053741455
Attempted to log scalar metric secsPerRoundTotal:
192.16022634506226
Sat Jun  3 06:52:10 2023 : ==== iteration 88
Sat Jun  3 06:52:10 2023 : Client learning rate 0.1
Sat Jun  3 06:52:10 2023 : Clients for round 100
Sat Jun  3 06:54:56 2023 : Updating model
Sat Jun  3 06:54:56 2023 : Updating learning rate scheduler
Sat Jun  3 06:54:56 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:54:56 2023 : Run ss scheduler
Sat Jun  3 06:54:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:54:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:54:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:54:57 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch88_model.tar
Sat Jun  3 06:54:58 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:54:58 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:54:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch88_best_val_acc_model.tar
Sat Jun  3 06:55:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch88_best_val_loss_model.tar
Sat Jun  3 06:55:01 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch88_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
88
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1336.115121126175
Attempted to log scalar metric secsPerRoundTotal:
170.64134526252747
Sat Jun  3 06:55:01 2023 : ==== iteration 89
Sat Jun  3 06:55:01 2023 : Client learning rate 0.1
Sat Jun  3 06:55:01 2023 : Clients for round 100
Sat Jun  3 06:58:48 2023 : Updating model
Sat Jun  3 06:58:48 2023 : Updating learning rate scheduler
Sat Jun  3 06:58:48 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 06:58:48 2023 : Run ss scheduler
Sat Jun  3 06:58:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 06:58:49 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:58:50 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:58:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch89_model.tar
Sat Jun  3 06:58:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:58:51 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 06:58:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch89_best_val_acc_model.tar
Sat Jun  3 06:58:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch89_best_val_loss_model.tar
Sat Jun  3 06:58:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch89_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
89
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1953.331746339798
Attempted to log scalar metric secsPerRoundTotal:
232.4990837574005
Sat Jun  3 06:58:53 2023 : ==== iteration 90
Sat Jun  3 06:58:53 2023 : Client learning rate 0.1
Sat Jun  3 06:58:53 2023 : Clients for round 100
Sat Jun  3 07:02:10 2023 : Updating model
Sat Jun  3 07:02:10 2023 : Updating learning rate scheduler
Sat Jun  3 07:02:10 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:02:10 2023 : Run ss scheduler
Sat Jun  3 07:02:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:02:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:02:11 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:02:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch90_model.tar
Sat Jun  3 07:02:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:02:12 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:02:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch90_best_val_acc_model.tar
Sat Jun  3 07:02:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch90_best_val_loss_model.tar
Sat Jun  3 07:02:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch90_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
90
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1686.976659655571
Attempted to log scalar metric secsPerRoundTotal:
202.01596117019653
Sat Jun  3 07:02:15 2023 : ==== iteration 91
Sat Jun  3 07:02:15 2023 : Client learning rate 0.1
Sat Jun  3 07:02:15 2023 : Clients for round 100
Sat Jun  3 07:05:24 2023 : Updating model
Sat Jun  3 07:05:24 2023 : Updating learning rate scheduler
Sat Jun  3 07:05:24 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:05:24 2023 : Run ss scheduler
Sat Jun  3 07:05:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:05:25 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:05:25 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:05:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch91_model.tar
Sat Jun  3 07:05:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:05:26 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:05:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch91_best_val_acc_model.tar
Sat Jun  3 07:05:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch91_best_val_loss_model.tar
Sat Jun  3 07:05:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch91_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
91
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1393.4731882810593
Attempted to log scalar metric secsPerRoundTotal:
193.50986576080322
Sat Jun  3 07:05:29 2023 : ==== iteration 92
Sat Jun  3 07:05:29 2023 : Client learning rate 0.1
Sat Jun  3 07:05:29 2023 : Clients for round 100
Sat Jun  3 07:09:29 2023 : Updating model
Sat Jun  3 07:09:29 2023 : Updating learning rate scheduler
Sat Jun  3 07:09:29 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:09:29 2023 : Run ss scheduler
Sat Jun  3 07:09:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:09:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:09:30 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:09:30 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch92_model.tar
Sat Jun  3 07:09:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:09:31 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:09:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch92_best_val_acc_model.tar
Sat Jun  3 07:09:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch92_best_val_loss_model.tar
Sat Jun  3 07:09:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch92_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
92
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1633.07803273201
Attempted to log scalar metric secsPerRoundTotal:
244.47038006782532
Sat Jun  3 07:09:33 2023 : ==== iteration 93
Sat Jun  3 07:09:33 2023 : Client learning rate 0.1
Sat Jun  3 07:09:33 2023 : Clients for round 100
Sat Jun  3 07:14:26 2023 : Updating model
Sat Jun  3 07:14:26 2023 : Updating learning rate scheduler
Sat Jun  3 07:14:26 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:14:26 2023 : Run ss scheduler
Sat Jun  3 07:14:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:14:27 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:14:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:14:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch93_model.tar
Sat Jun  3 07:14:28 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:14:29 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:14:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch93_best_val_acc_model.tar
Sat Jun  3 07:14:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch93_best_val_loss_model.tar
Sat Jun  3 07:14:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch93_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
93
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1776.4863567352295
Attempted to log scalar metric secsPerRoundTotal:
297.80572962760925
Sat Jun  3 07:14:31 2023 : ==== iteration 94
Sat Jun  3 07:14:31 2023 : Client learning rate 0.1
Sat Jun  3 07:14:31 2023 : Clients for round 100
Sat Jun  3 07:17:13 2023 : Updating model
Sat Jun  3 07:17:13 2023 : Updating learning rate scheduler
Sat Jun  3 07:17:13 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:17:13 2023 : Run ss scheduler
Sat Jun  3 07:17:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:17:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:17:14 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:17:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch94_model.tar
Sat Jun  3 07:17:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:17:15 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:17:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch94_best_val_acc_model.tar
Sat Jun  3 07:17:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch94_best_val_loss_model.tar
Sat Jun  3 07:17:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch94_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
94
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1311.483041524887
Attempted to log scalar metric secsPerRoundTotal:
166.45894813537598
Sat Jun  3 07:17:17 2023 : ==== iteration 95
Sat Jun  3 07:17:17 2023 : Client learning rate 0.1
Sat Jun  3 07:17:17 2023 : Clients for round 100
Sat Jun  3 07:20:01 2023 : Updating model
Sat Jun  3 07:20:01 2023 : Updating learning rate scheduler
Sat Jun  3 07:20:01 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:20:01 2023 : Run ss scheduler
Sat Jun  3 07:20:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:20:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:20:02 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:20:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch95_model.tar
Sat Jun  3 07:20:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:20:03 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:20:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch95_best_val_acc_model.tar
Sat Jun  3 07:20:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch95_best_val_loss_model.tar
Sat Jun  3 07:20:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch95_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
95
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1651.6616871356964
Attempted to log scalar metric secsPerRoundTotal:
168.09934282302856
Sat Jun  3 07:20:05 2023 : ==== iteration 96
Sat Jun  3 07:20:05 2023 : Client learning rate 0.1
Sat Jun  3 07:20:05 2023 : Clients for round 100
Sat Jun  3 07:22:52 2023 : Updating model
Sat Jun  3 07:22:52 2023 : Updating learning rate scheduler
Sat Jun  3 07:22:52 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:22:52 2023 : Run ss scheduler
Sat Jun  3 07:22:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:22:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:22:53 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:22:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch96_model.tar
Sat Jun  3 07:22:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:22:54 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:22:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch96_best_val_acc_model.tar
Sat Jun  3 07:22:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch96_best_val_loss_model.tar
Sat Jun  3 07:22:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch96_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
96
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1309.8158888816833
Attempted to log scalar metric secsPerRoundTotal:
170.8167052268982
Sat Jun  3 07:22:56 2023 : ==== iteration 97
Sat Jun  3 07:22:56 2023 : Client learning rate 0.1
Sat Jun  3 07:22:56 2023 : Clients for round 100
Sat Jun  3 07:25:33 2023 : Updating model
Sat Jun  3 07:25:33 2023 : Updating learning rate scheduler
Sat Jun  3 07:25:33 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:25:33 2023 : Run ss scheduler
Sat Jun  3 07:25:33 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:25:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:25:34 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:25:34 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch97_model.tar
Sat Jun  3 07:25:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:25:35 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:25:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch97_best_val_acc_model.tar
Sat Jun  3 07:25:37 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch97_best_val_loss_model.tar
Sat Jun  3 07:25:38 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch97_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
97
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1530.2198693752289
Attempted to log scalar metric secsPerRoundTotal:
161.618665933609
Sat Jun  3 07:25:38 2023 : ==== iteration 98
Sat Jun  3 07:25:38 2023 : Client learning rate 0.1
Sat Jun  3 07:25:38 2023 : Clients for round 100
Sat Jun  3 07:29:45 2023 : Updating model
Sat Jun  3 07:29:45 2023 : Updating learning rate scheduler
Sat Jun  3 07:29:45 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:29:45 2023 : Run ss scheduler
Sat Jun  3 07:29:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:29:46 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:29:46 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:29:46 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch98_model.tar
Sat Jun  3 07:29:47 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:29:47 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:29:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch98_best_val_acc_model.tar
Sat Jun  3 07:29:49 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch98_best_val_loss_model.tar
Sat Jun  3 07:29:50 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch98_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
98
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1969.837014079094
Attempted to log scalar metric secsPerRoundTotal:
252.1431109905243
Sat Jun  3 07:29:50 2023 : ==== iteration 99
Sat Jun  3 07:29:50 2023 : Client learning rate 0.1
Sat Jun  3 07:29:50 2023 : Clients for round 100
Sat Jun  3 07:32:56 2023 : Updating model
Sat Jun  3 07:32:56 2023 : Updating learning rate scheduler
Sat Jun  3 07:32:56 2023 : LR BEFORE lr_scheduler step: 1.0
Sat Jun  3 07:32:56 2023 : Run ss scheduler
Sat Jun  3 07:32:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/latest_model.tar
Sat Jun  3 07:32:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:32:57 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:32:57 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch99_model.tar
Sat Jun  3 07:32:58 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:32:58 2023 : Write operation succeeded in 1 attempts
Sat Jun  3 07:32:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch99_best_val_acc_model.tar
Sat Jun  3 07:32:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch99_best_val_loss_model.tar
Sat Jun  3 07:33:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-03 02:03:53.467877/f23c-46f8/models/epoch99_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
99
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1537.0266644954681
Attempted to log scalar metric secsPerRoundTotal:
190.21962118148804
Sat Jun  3 07:33:00 2023 : server terminated

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: ngongotaha: task 5: Exited with exit code 2

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
2441525
srun: error: mauao: task 1: Exited with exit code 2

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: ngongotaha: task 4: Exited with exit code 2
1699531
