WORLD_SIZE=6
MASTER_ADDR=mauao
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'max_grad_norm', 'num_workers', 'max_batch_size', 'num_frames', 'unsorted_batch', 'prepend_datapath', 'pin_memory'} in [server_config][val][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'max_grad_norm', 'num_workers', 'max_batch_size', 'num_frames', 'unsorted_batch', 'prepend_datapath', 'pin_memory'} in [server_config][test][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'max_grad_norm', 'num_workers', 'max_batch_size', 'num_frames', 'unsorted_batch', 'prepend_datapath', 'pin_memory'} in [client_config][train][data_config]
Fri Jun  2 19:18:08 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:08 2023 : Backend: nccl
Fri Jun  2 19:18:08 2023 : WORLD_RANK: 2
Fri Jun  2 19:18:08 2023 : LOCAL_RANK: 2
Fri Jun  2 19:18:08 2023 : NODE_NAME: mauao
Fri Jun  2 19:18:08 2023 : LOCAL_RANK_LIMIT: 2
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'pin_memory', 'max_batch_size', 'num_workers', 'prepend_datapath', 'unsorted_batch', 'num_frames', 'max_grad_norm'} in [server_config][val][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'pin_memory', 'max_batch_size', 'num_workers', 'prepend_datapath', 'unsorted_batch', 'num_frames', 'max_grad_norm'} in [server_config][test][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'pin_memory', 'max_batch_size', 'num_workers', 'prepend_datapath', 'unsorted_batch', 'num_frames', 'max_grad_norm'} in [client_config][train][data_config]
Fri Jun  2 19:18:08 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:08 2023 : Backend: nccl
Fri Jun  2 19:18:08 2023 : WORLD_RANK: 0
Fri Jun  2 19:18:08 2023 : LOCAL_RANK: 0
Fri Jun  2 19:18:08 2023 : NODE_NAME: mauao
Fri Jun  2 19:18:08 2023 : LOCAL_RANK_LIMIT: 2
Fri Jun  2 19:18:08 2023 : Passed
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'num_workers', 'unsorted_batch', 'prepend_datapath', 'max_batch_size', 'max_grad_norm', 'pin_memory', 'num_frames'} in [server_config][val][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'num_workers', 'unsorted_batch', 'prepend_datapath', 'max_batch_size', 'max_grad_norm', 'pin_memory', 'num_frames'} in [server_config][test][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'num_workers', 'unsorted_batch', 'prepend_datapath', 'max_batch_size', 'max_grad_norm', 'pin_memory', 'num_frames'} in [client_config][train][data_config]
Fri Jun  2 19:18:08 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:08 2023 : Backend: nccl
Fri Jun  2 19:18:08 2023 : WORLD_RANK: 3
Fri Jun  2 19:18:08 2023 : LOCAL_RANK: 3
Fri Jun  2 19:18:08 2023 : NODE_NAME: mauao
Fri Jun  2 19:18:08 2023 : LOCAL_RANK_LIMIT: 2
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'pin_memory', 'prepend_datapath', 'num_workers', 'unsorted_batch', 'max_batch_size', 'num_frames', 'max_grad_norm'} in [server_config][val][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'prepend_datapath', 'num_workers', 'unsorted_batch', 'max_batch_size', 'num_frames', 'max_grad_norm', 'pin_memory'} in [server_config][test][data_config]
Fri Jun  2 19:18:08 2023 : Assigning default values for: {'prepend_datapath', 'num_workers', 'unsorted_batch', 'max_batch_size', 'num_frames', 'max_grad_norm', 'pin_memory'} in [client_config][train][data_config]
Fri Jun  2 19:18:08 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:08 2023 : Backend: nccl
Fri Jun  2 19:18:08 2023 : WORLD_RANK: 1
Fri Jun  2 19:18:08 2023 : LOCAL_RANK: 1
Fri Jun  2 19:18:08 2023 : NODE_NAME: mauao
Fri Jun  2 19:18:08 2023 : LOCAL_RANK_LIMIT: 2
Fri Jun  2 19:18:08 2023 : Passed
Added key: store_based_barrier_key:1 to store for rank: 1

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: mauao: task 2: Exited with exit code 2
srun: error: mauao: task 3: Exited with exit code 2
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/nfs-share/aai30/miniconda3/envs/Flute/lib/python3.10/site-packages), Requirement.parse('packaging<22.0,>=20.0')).
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_batch_size', 'prepend_datapath', 'max_grad_norm', 'num_workers', 'unsorted_batch', 'num_frames', 'pin_memory'} in [server_config][val][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_batch_size', 'prepend_datapath', 'max_grad_norm', 'num_workers', 'unsorted_batch', 'num_frames', 'pin_memory'} in [server_config][test][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'prepend_datapath', 'max_batch_size', 'max_grad_norm', 'num_workers', 'unsorted_batch', 'num_frames', 'pin_memory'} in [client_config][train][data_config]
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_grad_norm', 'unsorted_batch', 'pin_memory', 'num_frames', 'prepend_datapath', 'max_batch_size', 'num_workers'} in [server_config][val][data_config]
Fri Jun  2 19:18:10 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_grad_norm', 'unsorted_batch', 'pin_memory', 'num_frames', 'prepend_datapath', 'max_batch_size', 'num_workers'} in [server_config][test][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_grad_norm', 'unsorted_batch', 'pin_memory', 'num_frames', 'prepend_datapath', 'max_batch_size', 'num_workers'} in [client_config][train][data_config]
Fri Jun  2 19:18:10 2023 : Backend: nccl
Fri Jun  2 19:18:10 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:10 2023 : WORLD_RANK: 2
Fri Jun  2 19:18:10 2023 : LOCAL_RANK: 2
Fri Jun  2 19:18:10 2023 : NODE_NAME: ngongotaha
Fri Jun  2 19:18:10 2023 : LOCAL_RANK_LIMIT: 4
Fri Jun  2 19:18:10 2023 : Backend: nccl
Fri Jun  2 19:18:10 2023 : Passed
Fri Jun  2 19:18:10 2023 : WORLD_RANK: 3
Fri Jun  2 19:18:10 2023 : LOCAL_RANK: 3
Fri Jun  2 19:18:10 2023 : NODE_NAME: ngongotaha
Fri Jun  2 19:18:10 2023 : LOCAL_RANK_LIMIT: 4
Fri Jun  2 19:18:10 2023 : Passed
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'prepend_datapath', 'unsorted_batch', 'max_batch_size', 'pin_memory', 'num_workers', 'num_frames', 'max_grad_norm'} in [server_config][val][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'prepend_datapath', 'unsorted_batch', 'max_batch_size', 'pin_memory', 'num_workers', 'num_frames', 'max_grad_norm'} in [server_config][test][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'prepend_datapath', 'unsorted_batch', 'max_batch_size', 'pin_memory', 'num_workers', 'num_frames', 'max_grad_norm'} in [client_config][train][data_config]
Fri Jun  2 19:18:10 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:10 2023 : Backend: nccl
Fri Jun  2 19:18:10 2023 : WORLD_RANK: 5
Fri Jun  2 19:18:10 2023 : LOCAL_RANK: 1
Fri Jun  2 19:18:10 2023 : NODE_NAME: ngongotaha
Fri Jun  2 19:18:10 2023 : LOCAL_RANK_LIMIT: 4
Fri Jun  2 19:18:10 2023 : Passed
{'outputPath': '/nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files', 'dataPath': '/datasets/FedScale/openImg', 'task': 'openImg', 'backend': 'nccl', 'num_skip_decoding': None, 'local_rank': None}
The data can be found here:  /datasets/FedScale/openImg
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'num_workers', 'unsorted_batch', 'max_grad_norm', 'pin_memory', 'prepend_datapath'} in [server_config][val][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'num_workers', 'unsorted_batch', 'max_grad_norm', 'pin_memory', 'prepend_datapath'} in [server_config][test][data_config]
Fri Jun  2 19:18:10 2023 : Assigning default values for: {'max_batch_size', 'num_frames', 'num_workers', 'unsorted_batch', 'max_grad_norm', 'prepend_datapath', 'pin_memory'} in [client_config][train][data_config]
Fri Jun  2 19:18:10 2023 : Warning: couldn't find ./experiments/openImg/config.py, falling back to dictionary.
Fri Jun  2 19:18:10 2023 : Backend: nccl
Fri Jun  2 19:18:10 2023 : WORLD_RANK: 4
Fri Jun  2 19:18:10 2023 : LOCAL_RANK: 0
Fri Jun  2 19:18:10 2023 : NODE_NAME: ngongotaha
Fri Jun  2 19:18:10 2023 : LOCAL_RANK_LIMIT: 4
Fri Jun  2 19:18:10 2023 : Passed
Added key: store_based_barrier_key:1 to store for rank: 0
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 5
Added key: store_based_barrier_key:1 to store for rank: 3
Added key: store_based_barrier_key:1 to store for rank: 4
Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Group initialized? True
Fri Jun  2 19:18:10 2023 : Master_node: mauao
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 0
Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 1
Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 2
Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 3
Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
Fri Jun  2 19:18:10 2023 : Assigning worker to GPU 1
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Preparing model .. Initializing
SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:11 2023 : initialize model with default settings
Fri Jun  2 19:18:11 2023 : trying to move the model to GPU
Fri Jun  2 19:18:14 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:14 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:14 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:14 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:14 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:14 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:14 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:14 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:14 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:15 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:15 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:15 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:15 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:15 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:15 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:15 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:15 2023 : Worker on node 2: process started
Fri Jun  2 19:18:15 2023 : Worker on node 5: process started
Fri Jun  2 19:18:15 2023 : Worker on node 3: process started
Fri Jun  2 19:18:15 2023 : Worker on node 4: process started
Fri Jun  2 19:18:17 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:17 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:17 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:17 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:17 2023 : model: SHUFFLENET(
  (net): ShuffleNetV2(
    (conv1): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (stage2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)
          (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)
          (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)
          (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (conv5): Sequential(
      (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
)
Fri Jun  2 19:18:17 2023 : torch.cuda.memory_allocated(): 29774336
Fri Jun  2 19:18:17 2023 : torch.cuda.memory_cached(): 35651584
Fri Jun  2 19:18:17 2023 : torch.cuda.synchronize(): None
Fri Jun  2 19:18:18 2023 : Server data preparation
Fri Jun  2 19:18:18 2023 : Prepared the dataloaders
Fri Jun  2 19:18:18 2023 : Loading Model from: None
Fri Jun  2 19:18:18 2023 : Using fast aggregation
Could not load the run context. Logging offline
Attempted to log scalar metric System memory (GB):
755.5415306091309
Attempted to log scalar metric server_config.num_clients_per_iteration:
100
Attempted to log scalar metric server_config.max_iteration:
100
Attempted to log scalar metric dp_config.eps:
0
Attempted to log scalar metric dp_config.max_weight:
0
Attempted to log scalar metric dp_config.min_weight:
0
Attempted to log scalar metric server_config.optimizer_config.type:
sgd
Attempted to log scalar metric server_config.optimizer_config.lr:
1.0
Attempted to log scalar metric server_config.optimizer_config.amsgrad:
False
Attempted to log scalar metric server_config.annealing_config.type:
none
Attempted to log scalar metric server_config.annealing_config.step_interval:
epoch
Attempted to log scalar metric server_config.annealing_config.gamma:
1.0
Attempted to log scalar metric server_config.annealing_config.step_size:
5000000
Fri Jun  2 19:18:18 2023 : Launching server
Fri Jun  2 19:18:18 2023 : server started
Attempted to log scalar metric Max iterations:
100
Fri Jun  2 19:18:18 2023 : Running [] at itr=0
Fri Jun  2 19:18:18 2023 : Saving Model Before Starting Training
Fri Jun  2 19:18:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/best_val_loss_model.tar
Fri Jun  2 19:18:18 2023 : Worker on node 1: process started
Fri Jun  2 19:18:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/best_val_acc_model.tar
Fri Jun  2 19:18:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/best_test_acc_model.tar
Fri Jun  2 19:18:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:18:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:18:22 2023 : ==== iteration 0
Fri Jun  2 19:18:22 2023 : Client learning rate 0.1
Fri Jun  2 19:18:22 2023 : Clients for round 100
Fri Jun  2 19:20:20 2023 : Updating model
Fri Jun  2 19:20:20 2023 : Updating learning rate scheduler
Fri Jun  2 19:20:20 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:20:20 2023 : Run ss scheduler
Fri Jun  2 19:20:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:20:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:20:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:20:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch0_model.tar
Fri Jun  2 19:20:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:20:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:20:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch0_best_val_acc_model.tar
Fri Jun  2 19:20:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch0_best_val_loss_model.tar
Fri Jun  2 19:20:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch0_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
0
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2295.901409626007
Attempted to log scalar metric secsPerRoundTotal:
122.81883454322815
Fri Jun  2 19:20:25 2023 : ==== iteration 1
Fri Jun  2 19:20:25 2023 : Client learning rate 0.1
Fri Jun  2 19:20:25 2023 : Clients for round 100
Fri Jun  2 19:22:47 2023 : Updating model
Fri Jun  2 19:22:47 2023 : Updating learning rate scheduler
Fri Jun  2 19:22:47 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:22:47 2023 : Run ss scheduler
Fri Jun  2 19:22:47 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:22:48 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:22:48 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:22:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch1_model.tar
Fri Jun  2 19:22:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:22:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:22:50 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch1_best_val_acc_model.tar
Fri Jun  2 19:22:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch1_best_val_loss_model.tar
Fri Jun  2 19:22:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch1_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
1
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2446.800561904907
Attempted to log scalar metric secsPerRoundTotal:
146.723974943161
Fri Jun  2 19:22:52 2023 : ==== iteration 2
Fri Jun  2 19:22:52 2023 : Client learning rate 0.1
Fri Jun  2 19:22:52 2023 : Clients for round 100
Fri Jun  2 19:25:39 2023 : Updating model
Fri Jun  2 19:25:39 2023 : Updating learning rate scheduler
Fri Jun  2 19:25:39 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:25:39 2023 : Run ss scheduler
Fri Jun  2 19:25:39 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:25:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:25:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:25:40 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch2_model.tar
Fri Jun  2 19:25:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:25:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:25:42 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch2_best_val_acc_model.tar
Fri Jun  2 19:25:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch2_best_val_loss_model.tar
Fri Jun  2 19:25:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch2_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
2
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2407.70117855072
Attempted to log scalar metric secsPerRoundTotal:
171.5916450023651
Fri Jun  2 19:25:43 2023 : ==== iteration 3
Fri Jun  2 19:25:43 2023 : Client learning rate 0.1
Fri Jun  2 19:25:43 2023 : Clients for round 100
Fri Jun  2 19:28:18 2023 : Updating model
Fri Jun  2 19:28:18 2023 : Updating learning rate scheduler
Fri Jun  2 19:28:18 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:28:18 2023 : Run ss scheduler
Fri Jun  2 19:28:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:28:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:28:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:28:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch3_model.tar
Fri Jun  2 19:28:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:28:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:28:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch3_best_val_acc_model.tar
Fri Jun  2 19:28:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch3_best_val_loss_model.tar
Fri Jun  2 19:28:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch3_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
3
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2069.4099566936493
Attempted to log scalar metric secsPerRoundTotal:
158.87158703804016
Fri Jun  2 19:28:22 2023 : ==== iteration 4
Fri Jun  2 19:28:22 2023 : Client learning rate 0.1
Fri Jun  2 19:28:22 2023 : Clients for round 100
Fri Jun  2 19:32:44 2023 : Updating model
Fri Jun  2 19:32:44 2023 : Updating learning rate scheduler
Fri Jun  2 19:32:44 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:32:44 2023 : Run ss scheduler
Fri Jun  2 19:32:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:32:45 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:32:45 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:32:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch4_model.tar
Fri Jun  2 19:32:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:32:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:32:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch4_best_val_acc_model.tar
Fri Jun  2 19:32:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch4_best_val_loss_model.tar
Fri Jun  2 19:32:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch4_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
4
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
3260.1905155181885
Attempted to log scalar metric secsPerRoundTotal:
265.48371028900146
Fri Jun  2 19:32:48 2023 : ==== iteration 5
Fri Jun  2 19:32:48 2023 : Client learning rate 0.1
Fri Jun  2 19:32:48 2023 : Clients for round 100
Fri Jun  2 19:35:15 2023 : Updating model
Fri Jun  2 19:35:15 2023 : Updating learning rate scheduler
Fri Jun  2 19:35:15 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:35:15 2023 : Run ss scheduler
Fri Jun  2 19:35:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:35:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:35:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:35:16 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch5_model.tar
Fri Jun  2 19:35:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:35:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:35:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch5_best_val_acc_model.tar
Fri Jun  2 19:35:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch5_best_val_loss_model.tar
Fri Jun  2 19:35:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch5_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
5
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2002.7873067855835
Attempted to log scalar metric secsPerRoundTotal:
151.94722175598145
Fri Jun  2 19:35:20 2023 : ==== iteration 6
Fri Jun  2 19:35:20 2023 : Client learning rate 0.1
Fri Jun  2 19:35:20 2023 : Clients for round 100
Fri Jun  2 19:38:03 2023 : Updating model
Fri Jun  2 19:38:03 2023 : Updating learning rate scheduler
Fri Jun  2 19:38:03 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:38:03 2023 : Run ss scheduler
Fri Jun  2 19:38:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:38:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:38:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:38:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch6_model.tar
Fri Jun  2 19:38:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:38:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:38:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch6_best_val_acc_model.tar
Fri Jun  2 19:38:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch6_best_val_loss_model.tar
Fri Jun  2 19:38:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch6_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
6
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2239.1274235248566
Attempted to log scalar metric secsPerRoundTotal:
168.1360263824463
Fri Jun  2 19:38:08 2023 : ==== iteration 7
Fri Jun  2 19:38:08 2023 : Client learning rate 0.1
Fri Jun  2 19:38:08 2023 : Clients for round 100
Fri Jun  2 19:40:05 2023 : Updating model
Fri Jun  2 19:40:05 2023 : Updating learning rate scheduler
Fri Jun  2 19:40:05 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:40:05 2023 : Run ss scheduler
Fri Jun  2 19:40:05 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:40:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:40:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:40:06 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch7_model.tar
Fri Jun  2 19:40:07 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:40:07 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:40:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch7_best_val_acc_model.tar
Fri Jun  2 19:40:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch7_best_val_loss_model.tar
Fri Jun  2 19:40:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch7_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
7
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1507.805594444275
Attempted to log scalar metric secsPerRoundTotal:
121.79750537872314
Fri Jun  2 19:40:10 2023 : ==== iteration 8
Fri Jun  2 19:40:10 2023 : Client learning rate 0.1
Fri Jun  2 19:40:10 2023 : Clients for round 100
Fri Jun  2 19:42:22 2023 : Updating model
Fri Jun  2 19:42:22 2023 : Updating learning rate scheduler
Fri Jun  2 19:42:22 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:42:22 2023 : Run ss scheduler
Fri Jun  2 19:42:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:42:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:42:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:42:23 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch8_model.tar
Fri Jun  2 19:42:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:42:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:42:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch8_best_val_acc_model.tar
Fri Jun  2 19:42:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch8_best_val_loss_model.tar
Fri Jun  2 19:42:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch8_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
8
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1745.7929680347443
Attempted to log scalar metric secsPerRoundTotal:
136.43615221977234
Fri Jun  2 19:42:26 2023 : ==== iteration 9
Fri Jun  2 19:42:26 2023 : Client learning rate 0.1
Fri Jun  2 19:42:26 2023 : Clients for round 100
Fri Jun  2 19:45:12 2023 : Updating model
Fri Jun  2 19:45:12 2023 : Updating learning rate scheduler
Fri Jun  2 19:45:12 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:45:12 2023 : Run ss scheduler
Fri Jun  2 19:45:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:45:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:45:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:45:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch9_model.tar
Fri Jun  2 19:45:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:45:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:45:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch9_best_val_acc_model.tar
Fri Jun  2 19:45:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch9_best_val_loss_model.tar
Fri Jun  2 19:45:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch9_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
9
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1857.2763907909393
Attempted to log scalar metric secsPerRoundTotal:
170.84382104873657
Fri Jun  2 19:45:17 2023 : ==== iteration 10
Fri Jun  2 19:45:17 2023 : Client learning rate 0.1
Fri Jun  2 19:45:17 2023 : Clients for round 100
Fri Jun  2 19:47:16 2023 : Updating model
Fri Jun  2 19:47:16 2023 : Updating learning rate scheduler
Fri Jun  2 19:47:16 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:47:16 2023 : Run ss scheduler
Fri Jun  2 19:47:16 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:47:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:47:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:47:17 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch10_model.tar
Fri Jun  2 19:47:18 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:47:18 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:47:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch10_best_val_acc_model.tar
Fri Jun  2 19:47:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch10_best_val_loss_model.tar
Fri Jun  2 19:47:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch10_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
10
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1666.5673134326935
Attempted to log scalar metric secsPerRoundTotal:
123.52349972724915
Fri Jun  2 19:47:20 2023 : ==== iteration 11
Fri Jun  2 19:47:20 2023 : Client learning rate 0.1
Fri Jun  2 19:47:20 2023 : Clients for round 100
Fri Jun  2 19:49:50 2023 : Updating model
Fri Jun  2 19:49:50 2023 : Updating learning rate scheduler
Fri Jun  2 19:49:50 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:49:50 2023 : Run ss scheduler
Fri Jun  2 19:49:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:49:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:49:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:49:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch11_model.tar
Fri Jun  2 19:49:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:49:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:49:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch11_best_val_acc_model.tar
Fri Jun  2 19:49:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch11_best_val_loss_model.tar
Fri Jun  2 19:49:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch11_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
11
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2047.8340289592743
Attempted to log scalar metric secsPerRoundTotal:
153.9558207988739
Fri Jun  2 19:49:54 2023 : ==== iteration 12
Fri Jun  2 19:49:54 2023 : Client learning rate 0.1
Fri Jun  2 19:49:54 2023 : Clients for round 100
Fri Jun  2 19:53:12 2023 : Updating model
Fri Jun  2 19:53:12 2023 : Updating learning rate scheduler
Fri Jun  2 19:53:12 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:53:12 2023 : Run ss scheduler
Fri Jun  2 19:53:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:53:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:53:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:53:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch12_model.tar
Fri Jun  2 19:53:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:53:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:53:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch12_best_val_acc_model.tar
Fri Jun  2 19:53:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch12_best_val_loss_model.tar
Fri Jun  2 19:53:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch12_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
12
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2555.8607308864594
Attempted to log scalar metric secsPerRoundTotal:
202.30250716209412
Fri Jun  2 19:53:17 2023 : ==== iteration 13
Fri Jun  2 19:53:17 2023 : Client learning rate 0.1
Fri Jun  2 19:53:17 2023 : Clients for round 100
Fri Jun  2 19:56:10 2023 : Updating model
Fri Jun  2 19:56:10 2023 : Updating learning rate scheduler
Fri Jun  2 19:56:10 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:56:10 2023 : Run ss scheduler
Fri Jun  2 19:56:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:56:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:56:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:56:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch13_model.tar
Fri Jun  2 19:56:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:56:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:56:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch13_best_val_acc_model.tar
Fri Jun  2 19:56:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch13_best_val_loss_model.tar
Fri Jun  2 19:56:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch13_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
13
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2357.249847650528
Attempted to log scalar metric secsPerRoundTotal:
178.1077606678009
Fri Jun  2 19:56:15 2023 : ==== iteration 14
Fri Jun  2 19:56:15 2023 : Client learning rate 0.1
Fri Jun  2 19:56:15 2023 : Clients for round 100
Fri Jun  2 19:58:50 2023 : Updating model
Fri Jun  2 19:58:50 2023 : Updating learning rate scheduler
Fri Jun  2 19:58:50 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 19:58:50 2023 : Run ss scheduler
Fri Jun  2 19:58:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 19:58:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:58:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:58:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch14_model.tar
Fri Jun  2 19:58:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:58:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 19:58:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch14_best_val_acc_model.tar
Fri Jun  2 19:58:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch14_best_val_loss_model.tar
Fri Jun  2 19:58:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch14_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
14
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2107.4283990859985
Attempted to log scalar metric secsPerRoundTotal:
159.84682369232178
Fri Jun  2 19:58:55 2023 : ==== iteration 15
Fri Jun  2 19:58:55 2023 : Client learning rate 0.1
Fri Jun  2 19:58:55 2023 : Clients for round 100
Fri Jun  2 20:01:08 2023 : Updating model
Fri Jun  2 20:01:08 2023 : Updating learning rate scheduler
Fri Jun  2 20:01:08 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:01:08 2023 : Run ss scheduler
Fri Jun  2 20:01:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:01:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:01:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:01:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch15_model.tar
Fri Jun  2 20:01:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:01:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:01:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch15_best_val_acc_model.tar
Fri Jun  2 20:01:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch15_best_val_loss_model.tar
Fri Jun  2 20:01:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch15_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
15
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1649.5344369411469
Attempted to log scalar metric secsPerRoundTotal:
138.32780766487122
Fri Jun  2 20:01:13 2023 : ==== iteration 16
Fri Jun  2 20:01:13 2023 : Client learning rate 0.1
Fri Jun  2 20:01:13 2023 : Clients for round 100
Fri Jun  2 20:03:08 2023 : Updating model
Fri Jun  2 20:03:08 2023 : Updating learning rate scheduler
Fri Jun  2 20:03:08 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:03:08 2023 : Run ss scheduler
Fri Jun  2 20:03:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:03:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:03:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:03:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch16_model.tar
Fri Jun  2 20:03:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:03:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:03:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch16_best_val_acc_model.tar
Fri Jun  2 20:03:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch16_best_val_loss_model.tar
Fri Jun  2 20:03:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch16_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
16
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1469.456494808197
Attempted to log scalar metric secsPerRoundTotal:
119.74003767967224
Fri Jun  2 20:03:13 2023 : ==== iteration 17
Fri Jun  2 20:03:13 2023 : Client learning rate 0.1
Fri Jun  2 20:03:13 2023 : Clients for round 100
Fri Jun  2 20:06:04 2023 : Updating model
Fri Jun  2 20:06:04 2023 : Updating learning rate scheduler
Fri Jun  2 20:06:04 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:06:04 2023 : Run ss scheduler
Fri Jun  2 20:06:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:06:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:06:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:06:05 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch17_model.tar
Fri Jun  2 20:06:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:06:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:06:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch17_best_val_acc_model.tar
Fri Jun  2 20:06:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch17_best_val_loss_model.tar
Fri Jun  2 20:06:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch17_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
17
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2153.2127459049225
Attempted to log scalar metric secsPerRoundTotal:
175.65876722335815
Fri Jun  2 20:06:08 2023 : ==== iteration 18
Fri Jun  2 20:06:08 2023 : Client learning rate 0.1
Fri Jun  2 20:06:08 2023 : Clients for round 100
Fri Jun  2 20:08:31 2023 : Updating model
Fri Jun  2 20:08:31 2023 : Updating learning rate scheduler
Fri Jun  2 20:08:31 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:08:31 2023 : Run ss scheduler
Fri Jun  2 20:08:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:08:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:08:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:08:32 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch18_model.tar
Fri Jun  2 20:08:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:08:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:08:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch18_best_val_acc_model.tar
Fri Jun  2 20:08:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch18_best_val_loss_model.tar
Fri Jun  2 20:08:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch18_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
18
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1723.8094947338104
Attempted to log scalar metric secsPerRoundTotal:
147.39180636405945
Fri Jun  2 20:08:36 2023 : ==== iteration 19
Fri Jun  2 20:08:36 2023 : Client learning rate 0.1
Fri Jun  2 20:08:36 2023 : Clients for round 100
Fri Jun  2 20:10:36 2023 : Updating model
Fri Jun  2 20:10:36 2023 : Updating learning rate scheduler
Fri Jun  2 20:10:36 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:10:36 2023 : Run ss scheduler
Fri Jun  2 20:10:36 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:10:37 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:10:37 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:10:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch19_model.tar
Fri Jun  2 20:10:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:10:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:10:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch19_best_val_acc_model.tar
Fri Jun  2 20:10:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch19_best_val_loss_model.tar
Fri Jun  2 20:10:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch19_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
19
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1309.5895206928253
Attempted to log scalar metric secsPerRoundTotal:
124.3223192691803
Fri Jun  2 20:10:40 2023 : ==== iteration 20
Fri Jun  2 20:10:40 2023 : Client learning rate 0.1
Fri Jun  2 20:10:40 2023 : Clients for round 100
Fri Jun  2 20:13:14 2023 : Updating model
Fri Jun  2 20:13:14 2023 : Updating learning rate scheduler
Fri Jun  2 20:13:14 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:13:14 2023 : Run ss scheduler
Fri Jun  2 20:13:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:13:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:13:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:13:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch20_model.tar
Fri Jun  2 20:13:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:13:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:13:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch20_best_val_acc_model.tar
Fri Jun  2 20:13:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch20_best_val_loss_model.tar
Fri Jun  2 20:13:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch20_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
20
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1948.2983164787292
Attempted to log scalar metric secsPerRoundTotal:
158.35486507415771
Fri Jun  2 20:13:18 2023 : ==== iteration 21
Fri Jun  2 20:13:18 2023 : Client learning rate 0.1
Fri Jun  2 20:13:18 2023 : Clients for round 100
Fri Jun  2 20:15:31 2023 : Updating model
Fri Jun  2 20:15:31 2023 : Updating learning rate scheduler
Fri Jun  2 20:15:31 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:15:31 2023 : Run ss scheduler
Fri Jun  2 20:15:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:15:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:15:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:15:32 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch21_model.tar
Fri Jun  2 20:15:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:15:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:15:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch21_best_val_acc_model.tar
Fri Jun  2 20:15:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch21_best_val_loss_model.tar
Fri Jun  2 20:15:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch21_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
21
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1665.379814863205
Attempted to log scalar metric secsPerRoundTotal:
137.06984496116638
Fri Jun  2 20:15:36 2023 : ==== iteration 22
Fri Jun  2 20:15:36 2023 : Client learning rate 0.1
Fri Jun  2 20:15:36 2023 : Clients for round 100
Fri Jun  2 20:17:37 2023 : Updating model
Fri Jun  2 20:17:37 2023 : Updating learning rate scheduler
Fri Jun  2 20:17:37 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:17:37 2023 : Run ss scheduler
Fri Jun  2 20:17:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:17:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:17:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:17:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch22_model.tar
Fri Jun  2 20:17:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:17:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:17:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch22_best_val_acc_model.tar
Fri Jun  2 20:17:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch22_best_val_loss_model.tar
Fri Jun  2 20:17:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch22_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
22
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1403.4586555957794
Attempted to log scalar metric secsPerRoundTotal:
125.76382899284363
Fri Jun  2 20:17:41 2023 : ==== iteration 23
Fri Jun  2 20:17:41 2023 : Client learning rate 0.1
Fri Jun  2 20:17:41 2023 : Clients for round 100
Fri Jun  2 20:19:51 2023 : Updating model
Fri Jun  2 20:19:51 2023 : Updating learning rate scheduler
Fri Jun  2 20:19:51 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:19:51 2023 : Run ss scheduler
Fri Jun  2 20:19:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:19:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:19:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:19:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch23_model.tar
Fri Jun  2 20:19:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:19:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:19:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch23_best_val_acc_model.tar
Fri Jun  2 20:19:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch23_best_val_loss_model.tar
Fri Jun  2 20:19:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch23_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
23
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1614.7571458816528
Attempted to log scalar metric secsPerRoundTotal:
134.09468865394592
Fri Jun  2 20:19:55 2023 : ==== iteration 24
Fri Jun  2 20:19:55 2023 : Client learning rate 0.1
Fri Jun  2 20:19:55 2023 : Clients for round 100
Fri Jun  2 20:23:20 2023 : Updating model
Fri Jun  2 20:23:20 2023 : Updating learning rate scheduler
Fri Jun  2 20:23:20 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:23:20 2023 : Run ss scheduler
Fri Jun  2 20:23:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:23:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:23:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:23:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch24_model.tar
Fri Jun  2 20:23:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:23:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:23:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch24_best_val_acc_model.tar
Fri Jun  2 20:23:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch24_best_val_loss_model.tar
Fri Jun  2 20:23:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch24_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
24
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1941.3612742424011
Attempted to log scalar metric secsPerRoundTotal:
209.0596218109131
Fri Jun  2 20:23:24 2023 : ==== iteration 25
Fri Jun  2 20:23:24 2023 : Client learning rate 0.1
Fri Jun  2 20:23:24 2023 : Clients for round 100
Fri Jun  2 20:26:11 2023 : Updating model
Fri Jun  2 20:26:11 2023 : Updating learning rate scheduler
Fri Jun  2 20:26:11 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:26:11 2023 : Run ss scheduler
Fri Jun  2 20:26:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:26:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:26:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:26:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch25_model.tar
Fri Jun  2 20:26:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:26:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:26:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch25_best_val_acc_model.tar
Fri Jun  2 20:26:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch25_best_val_loss_model.tar
Fri Jun  2 20:26:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch25_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
25
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2160.941689968109
Attempted to log scalar metric secsPerRoundTotal:
170.8356065750122
Fri Jun  2 20:26:15 2023 : ==== iteration 26
Fri Jun  2 20:26:15 2023 : Client learning rate 0.1
Fri Jun  2 20:26:15 2023 : Clients for round 100
Fri Jun  2 20:28:51 2023 : Updating model
Fri Jun  2 20:28:51 2023 : Updating learning rate scheduler
Fri Jun  2 20:28:51 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:28:51 2023 : Run ss scheduler
Fri Jun  2 20:28:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:28:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:28:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:28:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch26_model.tar
Fri Jun  2 20:28:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:28:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:28:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch26_best_val_acc_model.tar
Fri Jun  2 20:28:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch26_best_val_loss_model.tar
Fri Jun  2 20:28:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch26_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
26
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1994.280687570572
Attempted to log scalar metric secsPerRoundTotal:
160.49586153030396
Fri Jun  2 20:28:56 2023 : ==== iteration 27
Fri Jun  2 20:28:56 2023 : Client learning rate 0.1
Fri Jun  2 20:28:56 2023 : Clients for round 100
Fri Jun  2 20:31:08 2023 : Updating model
Fri Jun  2 20:31:08 2023 : Updating learning rate scheduler
Fri Jun  2 20:31:08 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:31:08 2023 : Run ss scheduler
Fri Jun  2 20:31:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:31:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:31:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:31:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch27_model.tar
Fri Jun  2 20:31:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:31:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:31:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch27_best_val_acc_model.tar
Fri Jun  2 20:31:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch27_best_val_loss_model.tar
Fri Jun  2 20:31:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch27_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
27
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1491.9916689395905
Attempted to log scalar metric secsPerRoundTotal:
136.82708096504211
Fri Jun  2 20:31:13 2023 : ==== iteration 28
Fri Jun  2 20:31:13 2023 : Client learning rate 0.1
Fri Jun  2 20:31:13 2023 : Clients for round 100
Fri Jun  2 20:33:24 2023 : Updating model
Fri Jun  2 20:33:24 2023 : Updating learning rate scheduler
Fri Jun  2 20:33:24 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:33:24 2023 : Run ss scheduler
Fri Jun  2 20:33:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:33:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:33:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:33:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch28_model.tar
Fri Jun  2 20:33:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:33:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:33:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch28_best_val_acc_model.tar
Fri Jun  2 20:33:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch28_best_val_loss_model.tar
Fri Jun  2 20:33:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch28_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
28
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1604.1891043186188
Attempted to log scalar metric secsPerRoundTotal:
136.07759547233582
Fri Jun  2 20:33:29 2023 : ==== iteration 29
Fri Jun  2 20:33:29 2023 : Client learning rate 0.1
Fri Jun  2 20:33:29 2023 : Clients for round 100
Fri Jun  2 20:35:48 2023 : Updating model
Fri Jun  2 20:35:48 2023 : Updating learning rate scheduler
Fri Jun  2 20:35:48 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:35:48 2023 : Run ss scheduler
Fri Jun  2 20:35:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:35:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:35:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:35:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch29_model.tar
Fri Jun  2 20:35:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:35:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:35:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch29_best_val_acc_model.tar
Fri Jun  2 20:35:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch29_best_val_loss_model.tar
Fri Jun  2 20:35:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch29_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
29
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1862.036912202835
Attempted to log scalar metric secsPerRoundTotal:
144.04902338981628
Fri Jun  2 20:35:53 2023 : ==== iteration 30
Fri Jun  2 20:35:53 2023 : Client learning rate 0.1
Fri Jun  2 20:35:53 2023 : Clients for round 100
Fri Jun  2 20:38:24 2023 : Updating model
Fri Jun  2 20:38:24 2023 : Updating learning rate scheduler
Fri Jun  2 20:38:24 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:38:24 2023 : Run ss scheduler
Fri Jun  2 20:38:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:38:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:38:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:38:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch30_model.tar
Fri Jun  2 20:38:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:38:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:38:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch30_best_val_acc_model.tar
Fri Jun  2 20:38:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch30_best_val_loss_model.tar
Fri Jun  2 20:38:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch30_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
30
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1658.6203129291534
Attempted to log scalar metric secsPerRoundTotal:
155.57347631454468
Fri Jun  2 20:38:28 2023 : ==== iteration 31
Fri Jun  2 20:38:28 2023 : Client learning rate 0.1
Fri Jun  2 20:38:28 2023 : Clients for round 100
Fri Jun  2 20:40:24 2023 : Updating model
Fri Jun  2 20:40:24 2023 : Updating learning rate scheduler
Fri Jun  2 20:40:24 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:40:24 2023 : Run ss scheduler
Fri Jun  2 20:40:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:40:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:40:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:40:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch31_model.tar
Fri Jun  2 20:40:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:40:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:40:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch31_best_val_acc_model.tar
Fri Jun  2 20:40:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch31_best_val_loss_model.tar
Fri Jun  2 20:40:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch31_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
31
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1204.5494859218597
Attempted to log scalar metric secsPerRoundTotal:
120.3556969165802
Fri Jun  2 20:40:29 2023 : ==== iteration 32
Fri Jun  2 20:40:29 2023 : Client learning rate 0.1
Fri Jun  2 20:40:29 2023 : Clients for round 100
Fri Jun  2 20:44:04 2023 : Updating model
Fri Jun  2 20:44:04 2023 : Updating learning rate scheduler
Fri Jun  2 20:44:04 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:44:04 2023 : Run ss scheduler
Fri Jun  2 20:44:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:44:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:44:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:44:05 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch32_model.tar
Fri Jun  2 20:44:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:44:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:44:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch32_best_val_acc_model.tar
Fri Jun  2 20:44:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch32_best_val_loss_model.tar
Fri Jun  2 20:44:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch32_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
32
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2228.4005222320557
Attempted to log scalar metric secsPerRoundTotal:
219.28134512901306
Fri Jun  2 20:44:08 2023 : ==== iteration 33
Fri Jun  2 20:44:08 2023 : Client learning rate 0.1
Fri Jun  2 20:44:08 2023 : Clients for round 100
Fri Jun  2 20:46:24 2023 : Updating model
Fri Jun  2 20:46:24 2023 : Updating learning rate scheduler
Fri Jun  2 20:46:24 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:46:24 2023 : Run ss scheduler
Fri Jun  2 20:46:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:46:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:46:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:46:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch33_model.tar
Fri Jun  2 20:46:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:46:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:46:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch33_best_val_acc_model.tar
Fri Jun  2 20:46:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch33_best_val_loss_model.tar
Fri Jun  2 20:46:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch33_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
33
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1693.4654738903046
Attempted to log scalar metric secsPerRoundTotal:
140.13357138633728
Fri Jun  2 20:46:28 2023 : ==== iteration 34
Fri Jun  2 20:46:28 2023 : Client learning rate 0.1
Fri Jun  2 20:46:28 2023 : Clients for round 100
Fri Jun  2 20:48:39 2023 : Updating model
Fri Jun  2 20:48:39 2023 : Updating learning rate scheduler
Fri Jun  2 20:48:39 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:48:39 2023 : Run ss scheduler
Fri Jun  2 20:48:39 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:48:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:48:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:48:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch34_model.tar
Fri Jun  2 20:48:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:48:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:48:42 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch34_best_val_acc_model.tar
Fri Jun  2 20:48:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch34_best_val_loss_model.tar
Fri Jun  2 20:48:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch34_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
34
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1408.6047866344452
Attempted to log scalar metric secsPerRoundTotal:
135.8109872341156
Fri Jun  2 20:48:44 2023 : ==== iteration 35
Fri Jun  2 20:48:44 2023 : Client learning rate 0.1
Fri Jun  2 20:48:44 2023 : Clients for round 100
Fri Jun  2 20:51:21 2023 : Updating model
Fri Jun  2 20:51:21 2023 : Updating learning rate scheduler
Fri Jun  2 20:51:21 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:51:21 2023 : Run ss scheduler
Fri Jun  2 20:51:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:51:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:51:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:51:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch35_model.tar
Fri Jun  2 20:51:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:51:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:51:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch35_best_val_acc_model.tar
Fri Jun  2 20:51:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch35_best_val_loss_model.tar
Fri Jun  2 20:51:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch35_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
35
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1951.882940530777
Attempted to log scalar metric secsPerRoundTotal:
161.29489421844482
Fri Jun  2 20:51:25 2023 : ==== iteration 36
Fri Jun  2 20:51:25 2023 : Client learning rate 0.1
Fri Jun  2 20:51:25 2023 : Clients for round 100
Fri Jun  2 20:53:57 2023 : Updating model
Fri Jun  2 20:53:57 2023 : Updating learning rate scheduler
Fri Jun  2 20:53:57 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:53:57 2023 : Run ss scheduler
Fri Jun  2 20:53:57 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:53:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:53:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:53:58 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch36_model.tar
Fri Jun  2 20:53:59 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:53:59 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:54:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch36_best_val_acc_model.tar
Fri Jun  2 20:54:01 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch36_best_val_loss_model.tar
Fri Jun  2 20:54:01 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch36_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
36
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1718.5530548095703
Attempted to log scalar metric secsPerRoundTotal:
156.32067847251892
Fri Jun  2 20:54:01 2023 : ==== iteration 37
Fri Jun  2 20:54:01 2023 : Client learning rate 0.1
Fri Jun  2 20:54:02 2023 : Clients for round 100
Fri Jun  2 20:56:42 2023 : Updating model
Fri Jun  2 20:56:42 2023 : Updating learning rate scheduler
Fri Jun  2 20:56:42 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:56:42 2023 : Run ss scheduler
Fri Jun  2 20:56:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:56:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:56:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:56:43 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch37_model.tar
Fri Jun  2 20:56:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:56:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:56:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch37_best_val_acc_model.tar
Fri Jun  2 20:56:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch37_best_val_loss_model.tar
Fri Jun  2 20:56:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch37_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
37
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1618.9432971477509
Attempted to log scalar metric secsPerRoundTotal:
164.9612579345703
Fri Jun  2 20:56:46 2023 : ==== iteration 38
Fri Jun  2 20:56:46 2023 : Client learning rate 0.1
Fri Jun  2 20:56:46 2023 : Clients for round 100
Fri Jun  2 20:58:34 2023 : Updating model
Fri Jun  2 20:58:34 2023 : Updating learning rate scheduler
Fri Jun  2 20:58:34 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 20:58:34 2023 : Run ss scheduler
Fri Jun  2 20:58:34 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 20:58:35 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:58:35 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:58:35 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch38_model.tar
Fri Jun  2 20:58:35 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:58:36 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 20:58:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch38_best_val_acc_model.tar
Fri Jun  2 20:58:37 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch38_best_val_loss_model.tar
Fri Jun  2 20:58:38 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch38_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
38
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1133.303772687912
Attempted to log scalar metric secsPerRoundTotal:
111.67505764961243
Fri Jun  2 20:58:38 2023 : ==== iteration 39
Fri Jun  2 20:58:38 2023 : Client learning rate 0.1
Fri Jun  2 20:58:38 2023 : Clients for round 100
Fri Jun  2 21:02:01 2023 : Updating model
Fri Jun  2 21:02:01 2023 : Updating learning rate scheduler
Fri Jun  2 21:02:01 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:02:01 2023 : Run ss scheduler
Fri Jun  2 21:02:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:02:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:02:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:02:02 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch39_model.tar
Fri Jun  2 21:02:03 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:02:03 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:02:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch39_best_val_acc_model.tar
Fri Jun  2 21:02:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch39_best_val_loss_model.tar
Fri Jun  2 21:02:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch39_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
39
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1964.125400543213
Attempted to log scalar metric secsPerRoundTotal:
207.44983172416687
Fri Jun  2 21:02:06 2023 : ==== iteration 40
Fri Jun  2 21:02:06 2023 : Client learning rate 0.1
Fri Jun  2 21:02:06 2023 : Clients for round 100
Fri Jun  2 21:05:21 2023 : Updating model
Fri Jun  2 21:05:21 2023 : Updating learning rate scheduler
Fri Jun  2 21:05:21 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:05:21 2023 : Run ss scheduler
Fri Jun  2 21:05:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:05:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:05:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:05:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch40_model.tar
Fri Jun  2 21:05:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:05:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:05:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch40_best_val_acc_model.tar
Fri Jun  2 21:05:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch40_best_val_loss_model.tar
Fri Jun  2 21:05:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch40_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
40
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2231.4294662475586
Attempted to log scalar metric secsPerRoundTotal:
200.17787623405457
Fri Jun  2 21:05:26 2023 : ==== iteration 41
Fri Jun  2 21:05:26 2023 : Client learning rate 0.1
Fri Jun  2 21:05:26 2023 : Clients for round 100
Fri Jun  2 21:08:38 2023 : Updating model
Fri Jun  2 21:08:38 2023 : Updating learning rate scheduler
Fri Jun  2 21:08:38 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:08:38 2023 : Run ss scheduler
Fri Jun  2 21:08:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:08:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:08:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:08:39 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch41_model.tar
Fri Jun  2 21:08:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:08:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:08:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch41_best_val_acc_model.tar
Fri Jun  2 21:08:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch41_best_val_loss_model.tar
Fri Jun  2 21:08:42 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch41_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
41
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2188.6364080905914
Attempted to log scalar metric secsPerRoundTotal:
196.4776430130005
Fri Jun  2 21:08:42 2023 : ==== iteration 42
Fri Jun  2 21:08:42 2023 : Client learning rate 0.1
Fri Jun  2 21:08:42 2023 : Clients for round 100
Fri Jun  2 21:11:00 2023 : Updating model
Fri Jun  2 21:11:00 2023 : Updating learning rate scheduler
Fri Jun  2 21:11:00 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:11:00 2023 : Run ss scheduler
Fri Jun  2 21:11:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:11:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:11:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:11:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch42_model.tar
Fri Jun  2 21:11:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:11:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:11:02 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch42_best_val_acc_model.tar
Fri Jun  2 21:11:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch42_best_val_loss_model.tar
Fri Jun  2 21:11:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch42_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
42
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1640.8608665466309
Attempted to log scalar metric secsPerRoundTotal:
141.8501696586609
Fri Jun  2 21:11:04 2023 : ==== iteration 43
Fri Jun  2 21:11:04 2023 : Client learning rate 0.1
Fri Jun  2 21:11:04 2023 : Clients for round 100
Fri Jun  2 21:13:59 2023 : Updating model
Fri Jun  2 21:13:59 2023 : Updating learning rate scheduler
Fri Jun  2 21:13:59 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:13:59 2023 : Run ss scheduler
Fri Jun  2 21:13:59 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:14:00 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:14:00 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:14:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch43_model.tar
Fri Jun  2 21:14:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:14:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:14:02 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch43_best_val_acc_model.tar
Fri Jun  2 21:14:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch43_best_val_loss_model.tar
Fri Jun  2 21:14:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch43_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
43
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2042.3026292324066
Attempted to log scalar metric secsPerRoundTotal:
179.56538701057434
Fri Jun  2 21:14:04 2023 : ==== iteration 44
Fri Jun  2 21:14:04 2023 : Client learning rate 0.1
Fri Jun  2 21:14:04 2023 : Clients for round 100
Fri Jun  2 21:16:37 2023 : Updating model
Fri Jun  2 21:16:37 2023 : Updating learning rate scheduler
Fri Jun  2 21:16:37 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:16:37 2023 : Run ss scheduler
Fri Jun  2 21:16:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:16:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:16:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:16:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch44_model.tar
Fri Jun  2 21:16:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:16:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:16:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch44_best_val_acc_model.tar
Fri Jun  2 21:16:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch44_best_val_loss_model.tar
Fri Jun  2 21:16:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch44_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
44
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1715.2980988025665
Attempted to log scalar metric secsPerRoundTotal:
157.72054862976074
Fri Jun  2 21:16:41 2023 : ==== iteration 45
Fri Jun  2 21:16:41 2023 : Client learning rate 0.1
Fri Jun  2 21:16:41 2023 : Clients for round 100
Fri Jun  2 21:19:13 2023 : Updating model
Fri Jun  2 21:19:13 2023 : Updating learning rate scheduler
Fri Jun  2 21:19:13 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:19:13 2023 : Run ss scheduler
Fri Jun  2 21:19:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:19:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:19:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:19:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch45_model.tar
Fri Jun  2 21:19:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:19:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:19:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch45_best_val_acc_model.tar
Fri Jun  2 21:19:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch45_best_val_loss_model.tar
Fri Jun  2 21:19:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch45_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
45
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1567.3263669013977
Attempted to log scalar metric secsPerRoundTotal:
155.94607949256897
Fri Jun  2 21:19:17 2023 : ==== iteration 46
Fri Jun  2 21:19:17 2023 : Client learning rate 0.1
Fri Jun  2 21:19:17 2023 : Clients for round 100
Fri Jun  2 21:22:04 2023 : Updating model
Fri Jun  2 21:22:04 2023 : Updating learning rate scheduler
Fri Jun  2 21:22:04 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:22:04 2023 : Run ss scheduler
Fri Jun  2 21:22:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:22:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:22:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:22:05 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch46_model.tar
Fri Jun  2 21:22:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:22:06 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:22:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch46_best_val_acc_model.tar
Fri Jun  2 21:22:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch46_best_val_loss_model.tar
Fri Jun  2 21:22:09 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch46_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
46
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1910.194040775299
Attempted to log scalar metric secsPerRoundTotal:
171.85919070243835
Fri Jun  2 21:22:09 2023 : ==== iteration 47
Fri Jun  2 21:22:09 2023 : Client learning rate 0.1
Fri Jun  2 21:22:09 2023 : Clients for round 100
Fri Jun  2 21:24:55 2023 : Updating model
Fri Jun  2 21:24:55 2023 : Updating learning rate scheduler
Fri Jun  2 21:24:55 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:24:55 2023 : Run ss scheduler
Fri Jun  2 21:24:55 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:24:56 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:24:56 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:24:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch47_model.tar
Fri Jun  2 21:24:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:24:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:24:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch47_best_val_acc_model.tar
Fri Jun  2 21:24:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch47_best_val_loss_model.tar
Fri Jun  2 21:25:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch47_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
47
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1855.5926189422607
Attempted to log scalar metric secsPerRoundTotal:
170.88400888442993
Fri Jun  2 21:25:00 2023 : ==== iteration 48
Fri Jun  2 21:25:00 2023 : Client learning rate 0.1
Fri Jun  2 21:25:00 2023 : Clients for round 100
Fri Jun  2 21:27:15 2023 : Updating model
Fri Jun  2 21:27:15 2023 : Updating learning rate scheduler
Fri Jun  2 21:27:15 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:27:15 2023 : Run ss scheduler
Fri Jun  2 21:27:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:27:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:27:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:27:17 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch48_model.tar
Fri Jun  2 21:27:17 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:27:18 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:27:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch48_best_val_acc_model.tar
Fri Jun  2 21:27:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch48_best_val_loss_model.tar
Fri Jun  2 21:27:20 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch48_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
48
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1532.4814916849136
Attempted to log scalar metric secsPerRoundTotal:
140.2426483631134
Fri Jun  2 21:27:20 2023 : ==== iteration 49
Fri Jun  2 21:27:20 2023 : Client learning rate 0.1
Fri Jun  2 21:27:20 2023 : Clients for round 100
Fri Jun  2 21:30:09 2023 : Updating model
Fri Jun  2 21:30:09 2023 : Updating learning rate scheduler
Fri Jun  2 21:30:09 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:30:09 2023 : Run ss scheduler
Fri Jun  2 21:30:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:30:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:30:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:30:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch49_model.tar
Fri Jun  2 21:30:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:30:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:30:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch49_best_val_acc_model.tar
Fri Jun  2 21:30:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch49_best_val_loss_model.tar
Fri Jun  2 21:30:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch49_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
49
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1954.2742006778717
Attempted to log scalar metric secsPerRoundTotal:
173.45030546188354
Fri Jun  2 21:30:14 2023 : ==== iteration 50
Fri Jun  2 21:30:14 2023 : Client learning rate 0.1
Fri Jun  2 21:30:14 2023 : Clients for round 100
Fri Jun  2 21:32:31 2023 : Updating model
Fri Jun  2 21:32:31 2023 : Updating learning rate scheduler
Fri Jun  2 21:32:31 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:32:31 2023 : Run ss scheduler
Fri Jun  2 21:32:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:32:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:32:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:32:32 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch50_model.tar
Fri Jun  2 21:32:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:32:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:32:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch50_best_val_acc_model.tar
Fri Jun  2 21:32:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch50_best_val_loss_model.tar
Fri Jun  2 21:32:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch50_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
50
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1388.3999285697937
Attempted to log scalar metric secsPerRoundTotal:
141.67534565925598
Fri Jun  2 21:32:35 2023 : ==== iteration 51
Fri Jun  2 21:32:35 2023 : Client learning rate 0.1
Fri Jun  2 21:32:35 2023 : Clients for round 100
Fri Jun  2 21:34:41 2023 : Updating model
Fri Jun  2 21:34:41 2023 : Updating learning rate scheduler
Fri Jun  2 21:34:41 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:34:41 2023 : Run ss scheduler
Fri Jun  2 21:34:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:34:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:34:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:34:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch51_model.tar
Fri Jun  2 21:34:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:34:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:34:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch51_best_val_acc_model.tar
Fri Jun  2 21:34:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch51_best_val_loss_model.tar
Fri Jun  2 21:34:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch51_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
51
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1317.2179691791534
Attempted to log scalar metric secsPerRoundTotal:
129.64514064788818
Fri Jun  2 21:34:45 2023 : ==== iteration 52
Fri Jun  2 21:34:45 2023 : Client learning rate 0.1
Fri Jun  2 21:34:45 2023 : Clients for round 100
Fri Jun  2 21:37:38 2023 : Updating model
Fri Jun  2 21:37:38 2023 : Updating learning rate scheduler
Fri Jun  2 21:37:38 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:37:38 2023 : Run ss scheduler
Fri Jun  2 21:37:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:37:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:37:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:37:39 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch52_model.tar
Fri Jun  2 21:37:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:37:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:37:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch52_best_val_acc_model.tar
Fri Jun  2 21:37:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch52_best_val_loss_model.tar
Fri Jun  2 21:37:42 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch52_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
52
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1822.0465722084045
Attempted to log scalar metric secsPerRoundTotal:
177.33263611793518
Fri Jun  2 21:37:42 2023 : ==== iteration 53
Fri Jun  2 21:37:42 2023 : Client learning rate 0.1
Fri Jun  2 21:37:42 2023 : Clients for round 100
Fri Jun  2 21:39:51 2023 : Updating model
Fri Jun  2 21:39:51 2023 : Updating learning rate scheduler
Fri Jun  2 21:39:51 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:39:51 2023 : Run ss scheduler
Fri Jun  2 21:39:51 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:39:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:39:52 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:39:52 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch53_model.tar
Fri Jun  2 21:39:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:39:53 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:39:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch53_best_val_acc_model.tar
Fri Jun  2 21:39:55 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch53_best_val_loss_model.tar
Fri Jun  2 21:39:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch53_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
53
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1345.0462017059326
Attempted to log scalar metric secsPerRoundTotal:
133.2529628276825
Fri Jun  2 21:39:56 2023 : ==== iteration 54
Fri Jun  2 21:39:56 2023 : Client learning rate 0.1
Fri Jun  2 21:39:56 2023 : Clients for round 100
Fri Jun  2 21:42:11 2023 : Updating model
Fri Jun  2 21:42:11 2023 : Updating learning rate scheduler
Fri Jun  2 21:42:11 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:42:11 2023 : Run ss scheduler
Fri Jun  2 21:42:11 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:42:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:42:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:42:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch54_model.tar
Fri Jun  2 21:42:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:42:12 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:42:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch54_best_val_acc_model.tar
Fri Jun  2 21:42:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch54_best_val_loss_model.tar
Fri Jun  2 21:42:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch54_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
54
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1424.8982115983963
Attempted to log scalar metric secsPerRoundTotal:
139.1505320072174
Fri Jun  2 21:42:15 2023 : ==== iteration 55
Fri Jun  2 21:42:15 2023 : Client learning rate 0.1
Fri Jun  2 21:42:15 2023 : Clients for round 100
Fri Jun  2 21:44:42 2023 : Updating model
Fri Jun  2 21:44:42 2023 : Updating learning rate scheduler
Fri Jun  2 21:44:42 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:44:42 2023 : Run ss scheduler
Fri Jun  2 21:44:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:44:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:44:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:44:43 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch55_model.tar
Fri Jun  2 21:44:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:44:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:44:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch55_best_val_acc_model.tar
Fri Jun  2 21:44:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch55_best_val_loss_model.tar
Fri Jun  2 21:44:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch55_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
55
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1528.0750161409378
Attempted to log scalar metric secsPerRoundTotal:
151.74798560142517
Fri Jun  2 21:44:47 2023 : ==== iteration 56
Fri Jun  2 21:44:47 2023 : Client learning rate 0.1
Fri Jun  2 21:44:47 2023 : Clients for round 100
Fri Jun  2 21:46:26 2023 : Updating model
Fri Jun  2 21:46:26 2023 : Updating learning rate scheduler
Fri Jun  2 21:46:26 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:46:26 2023 : Run ss scheduler
Fri Jun  2 21:46:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:46:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:46:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:46:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch56_model.tar
Fri Jun  2 21:46:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:46:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:46:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch56_best_val_acc_model.tar
Fri Jun  2 21:46:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch56_best_val_loss_model.tar
Fri Jun  2 21:46:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch56_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
56
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1135.8794504404068
Attempted to log scalar metric secsPerRoundTotal:
104.26058721542358
Fri Jun  2 21:46:31 2023 : ==== iteration 57
Fri Jun  2 21:46:31 2023 : Client learning rate 0.1
Fri Jun  2 21:46:31 2023 : Clients for round 100
Fri Jun  2 21:49:37 2023 : Updating model
Fri Jun  2 21:49:37 2023 : Updating learning rate scheduler
Fri Jun  2 21:49:37 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:49:37 2023 : Run ss scheduler
Fri Jun  2 21:49:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:49:37 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:49:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:49:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch57_model.tar
Fri Jun  2 21:49:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:49:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:49:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch57_best_val_acc_model.tar
Fri Jun  2 21:49:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch57_best_val_loss_model.tar
Fri Jun  2 21:49:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch57_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
57
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1574.8951033353806
Attempted to log scalar metric secsPerRoundTotal:
190.3883273601532
Fri Jun  2 21:49:41 2023 : ==== iteration 58
Fri Jun  2 21:49:41 2023 : Client learning rate 0.1
Fri Jun  2 21:49:41 2023 : Clients for round 100
Fri Jun  2 21:52:03 2023 : Updating model
Fri Jun  2 21:52:03 2023 : Updating learning rate scheduler
Fri Jun  2 21:52:03 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:52:03 2023 : Run ss scheduler
Fri Jun  2 21:52:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:52:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:52:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:52:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch58_model.tar
Fri Jun  2 21:52:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:52:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:52:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch58_best_val_acc_model.tar
Fri Jun  2 21:52:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch58_best_val_loss_model.tar
Fri Jun  2 21:52:08 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch58_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
58
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1555.0090522766113
Attempted to log scalar metric secsPerRoundTotal:
146.34947228431702
Fri Jun  2 21:52:08 2023 : ==== iteration 59
Fri Jun  2 21:52:08 2023 : Client learning rate 0.1
Fri Jun  2 21:52:08 2023 : Clients for round 100
Fri Jun  2 21:55:03 2023 : Updating model
Fri Jun  2 21:55:03 2023 : Updating learning rate scheduler
Fri Jun  2 21:55:03 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:55:03 2023 : Run ss scheduler
Fri Jun  2 21:55:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:55:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:55:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:55:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch59_model.tar
Fri Jun  2 21:55:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:55:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:55:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch59_best_val_acc_model.tar
Fri Jun  2 21:55:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch59_best_val_loss_model.tar
Fri Jun  2 21:55:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch59_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
59
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1256.7817063331604
Attempted to log scalar metric secsPerRoundTotal:
179.73168516159058
Fri Jun  2 21:55:07 2023 : ==== iteration 60
Fri Jun  2 21:55:07 2023 : Client learning rate 0.1
Fri Jun  2 21:55:07 2023 : Clients for round 100
Fri Jun  2 21:57:20 2023 : Updating model
Fri Jun  2 21:57:20 2023 : Updating learning rate scheduler
Fri Jun  2 21:57:20 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:57:20 2023 : Run ss scheduler
Fri Jun  2 21:57:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:57:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:57:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:57:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch60_model.tar
Fri Jun  2 21:57:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:57:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:57:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch60_best_val_acc_model.tar
Fri Jun  2 21:57:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch60_best_val_loss_model.tar
Fri Jun  2 21:57:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch60_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
60
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1405.7167797088623
Attempted to log scalar metric secsPerRoundTotal:
136.7856945991516
Fri Jun  2 21:57:24 2023 : ==== iteration 61
Fri Jun  2 21:57:24 2023 : Client learning rate 0.1
Fri Jun  2 21:57:24 2023 : Clients for round 100
Fri Jun  2 21:59:20 2023 : Updating model
Fri Jun  2 21:59:20 2023 : Updating learning rate scheduler
Fri Jun  2 21:59:20 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 21:59:20 2023 : Run ss scheduler
Fri Jun  2 21:59:20 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 21:59:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:59:21 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:59:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch61_model.tar
Fri Jun  2 21:59:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:59:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 21:59:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch61_best_val_acc_model.tar
Fri Jun  2 21:59:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch61_best_val_loss_model.tar
Fri Jun  2 21:59:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch61_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
61
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1297.8829978704453
Attempted to log scalar metric secsPerRoundTotal:
120.58982062339783
Fri Jun  2 21:59:25 2023 : ==== iteration 62
Fri Jun  2 21:59:25 2023 : Client learning rate 0.1
Fri Jun  2 21:59:25 2023 : Clients for round 100
Fri Jun  2 22:02:00 2023 : Updating model
Fri Jun  2 22:02:00 2023 : Updating learning rate scheduler
Fri Jun  2 22:02:00 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:02:00 2023 : Run ss scheduler
Fri Jun  2 22:02:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:02:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:02:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:02:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch62_model.tar
Fri Jun  2 22:02:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:02:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:02:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch62_best_val_acc_model.tar
Fri Jun  2 22:02:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch62_best_val_loss_model.tar
Fri Jun  2 22:02:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch62_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
62
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1711.7557017803192
Attempted to log scalar metric secsPerRoundTotal:
159.842351436615
Fri Jun  2 22:02:05 2023 : ==== iteration 63
Fri Jun  2 22:02:05 2023 : Client learning rate 0.1
Fri Jun  2 22:02:05 2023 : Clients for round 100
Fri Jun  2 22:05:25 2023 : Updating model
Fri Jun  2 22:05:25 2023 : Updating learning rate scheduler
Fri Jun  2 22:05:25 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:05:25 2023 : Run ss scheduler
Fri Jun  2 22:05:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:05:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:05:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:05:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch63_model.tar
Fri Jun  2 22:05:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:05:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:05:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch63_best_val_acc_model.tar
Fri Jun  2 22:05:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch63_best_val_loss_model.tar
Fri Jun  2 22:05:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch63_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
63
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2116.2620631456375
Attempted to log scalar metric secsPerRoundTotal:
204.99237203598022
Fri Jun  2 22:05:29 2023 : ==== iteration 64
Fri Jun  2 22:05:29 2023 : Client learning rate 0.1
Fri Jun  2 22:05:30 2023 : Clients for round 100
Fri Jun  2 22:08:09 2023 : Updating model
Fri Jun  2 22:08:09 2023 : Updating learning rate scheduler
Fri Jun  2 22:08:09 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:08:09 2023 : Run ss scheduler
Fri Jun  2 22:08:09 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:08:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:08:10 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:08:10 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch64_model.tar
Fri Jun  2 22:08:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:08:11 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:08:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch64_best_val_acc_model.tar
Fri Jun  2 22:08:13 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch64_best_val_loss_model.tar
Fri Jun  2 22:08:14 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch64_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
64
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1843.4100486040115
Attempted to log scalar metric secsPerRoundTotal:
164.23407864570618
Fri Jun  2 22:08:14 2023 : ==== iteration 65
Fri Jun  2 22:08:14 2023 : Client learning rate 0.1
Fri Jun  2 22:08:14 2023 : Clients for round 100
Fri Jun  2 22:10:49 2023 : Updating model
Fri Jun  2 22:10:49 2023 : Updating learning rate scheduler
Fri Jun  2 22:10:49 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:10:49 2023 : Run ss scheduler
Fri Jun  2 22:10:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:10:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:10:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:10:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch65_model.tar
Fri Jun  2 22:10:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:10:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:10:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch65_best_val_acc_model.tar
Fri Jun  2 22:10:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch65_best_val_loss_model.tar
Fri Jun  2 22:10:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch65_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
65
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1511.3258012533188
Attempted to log scalar metric secsPerRoundTotal:
159.97639632225037
Fri Jun  2 22:10:54 2023 : ==== iteration 66
Fri Jun  2 22:10:54 2023 : Client learning rate 0.1
Fri Jun  2 22:10:54 2023 : Clients for round 100
Fri Jun  2 22:13:00 2023 : Updating model
Fri Jun  2 22:13:00 2023 : Updating learning rate scheduler
Fri Jun  2 22:13:00 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:13:00 2023 : Run ss scheduler
Fri Jun  2 22:13:00 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:13:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:13:01 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:13:01 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch66_model.tar
Fri Jun  2 22:13:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:13:02 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:13:03 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch66_best_val_acc_model.tar
Fri Jun  2 22:13:04 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch66_best_val_loss_model.tar
Fri Jun  2 22:13:05 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch66_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
66
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1389.2536981105804
Attempted to log scalar metric secsPerRoundTotal:
130.96160173416138
Fri Jun  2 22:13:05 2023 : ==== iteration 67
Fri Jun  2 22:13:05 2023 : Client learning rate 0.1
Fri Jun  2 22:13:05 2023 : Clients for round 100
Fri Jun  2 22:16:21 2023 : Updating model
Fri Jun  2 22:16:21 2023 : Updating learning rate scheduler
Fri Jun  2 22:16:21 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:16:21 2023 : Run ss scheduler
Fri Jun  2 22:16:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:16:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:16:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:16:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch67_model.tar
Fri Jun  2 22:16:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:16:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:16:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch67_best_val_acc_model.tar
Fri Jun  2 22:16:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch67_best_val_loss_model.tar
Fri Jun  2 22:16:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch67_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
67
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
2079.2358932495117
Attempted to log scalar metric secsPerRoundTotal:
200.60515069961548
Fri Jun  2 22:16:25 2023 : ==== iteration 68
Fri Jun  2 22:16:25 2023 : Client learning rate 0.1
Fri Jun  2 22:16:25 2023 : Clients for round 100
Fri Jun  2 22:18:27 2023 : Updating model
Fri Jun  2 22:18:27 2023 : Updating learning rate scheduler
Fri Jun  2 22:18:27 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:18:27 2023 : Run ss scheduler
Fri Jun  2 22:18:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:18:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:18:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:18:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch68_model.tar
Fri Jun  2 22:18:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:18:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:18:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch68_best_val_acc_model.tar
Fri Jun  2 22:18:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch68_best_val_loss_model.tar
Fri Jun  2 22:18:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch68_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
68
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1273.8497831821442
Attempted to log scalar metric secsPerRoundTotal:
126.0053596496582
Fri Jun  2 22:18:31 2023 : ==== iteration 69
Fri Jun  2 22:18:31 2023 : Client learning rate 0.1
Fri Jun  2 22:18:31 2023 : Clients for round 100
Fri Jun  2 22:20:24 2023 : Updating model
Fri Jun  2 22:20:24 2023 : Updating learning rate scheduler
Fri Jun  2 22:20:24 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:20:24 2023 : Run ss scheduler
Fri Jun  2 22:20:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:20:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:20:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:20:25 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch69_model.tar
Fri Jun  2 22:20:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:20:26 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:20:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch69_best_val_acc_model.tar
Fri Jun  2 22:20:28 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch69_best_val_loss_model.tar
Fri Jun  2 22:20:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch69_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
69
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1065.8312338590622
Attempted to log scalar metric secsPerRoundTotal:
117.30844259262085
Fri Jun  2 22:20:29 2023 : ==== iteration 70
Fri Jun  2 22:20:29 2023 : Client learning rate 0.1
Fri Jun  2 22:20:29 2023 : Clients for round 100
Fri Jun  2 22:22:28 2023 : Updating model
Fri Jun  2 22:22:29 2023 : Updating learning rate scheduler
Fri Jun  2 22:22:29 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:22:29 2023 : Run ss scheduler
Fri Jun  2 22:22:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:22:30 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:22:30 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:22:30 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch70_model.tar
Fri Jun  2 22:22:31 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:22:31 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:22:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch70_best_val_acc_model.tar
Fri Jun  2 22:22:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch70_best_val_loss_model.tar
Fri Jun  2 22:22:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch70_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
70
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1283.5155413150787
Attempted to log scalar metric secsPerRoundTotal:
124.5632631778717
Fri Jun  2 22:22:33 2023 : ==== iteration 71
Fri Jun  2 22:22:33 2023 : Client learning rate 0.1
Fri Jun  2 22:22:33 2023 : Clients for round 100
Fri Jun  2 22:25:28 2023 : Updating model
Fri Jun  2 22:25:28 2023 : Updating learning rate scheduler
Fri Jun  2 22:25:28 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:25:28 2023 : Run ss scheduler
Fri Jun  2 22:25:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:25:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:25:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:25:29 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch71_model.tar
Fri Jun  2 22:25:30 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:25:30 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:25:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch71_best_val_acc_model.tar
Fri Jun  2 22:25:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch71_best_val_loss_model.tar
Fri Jun  2 22:25:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch71_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
71
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1752.9091308116913
Attempted to log scalar metric secsPerRoundTotal:
179.99543619155884
Fri Jun  2 22:25:33 2023 : ==== iteration 72
Fri Jun  2 22:25:33 2023 : Client learning rate 0.1
Fri Jun  2 22:25:33 2023 : Clients for round 100
Fri Jun  2 22:28:18 2023 : Updating model
Fri Jun  2 22:28:18 2023 : Updating learning rate scheduler
Fri Jun  2 22:28:18 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:28:18 2023 : Run ss scheduler
Fri Jun  2 22:28:18 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:28:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:28:19 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:28:19 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch72_model.tar
Fri Jun  2 22:28:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:28:20 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:28:21 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch72_best_val_acc_model.tar
Fri Jun  2 22:28:22 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch72_best_val_loss_model.tar
Fri Jun  2 22:28:23 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch72_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
72
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1858.5710262060165
Attempted to log scalar metric secsPerRoundTotal:
169.90918040275574
Fri Jun  2 22:28:23 2023 : ==== iteration 73
Fri Jun  2 22:28:23 2023 : Client learning rate 0.1
Fri Jun  2 22:28:23 2023 : Clients for round 100
Fri Jun  2 22:30:45 2023 : Updating model
Fri Jun  2 22:30:45 2023 : Updating learning rate scheduler
Fri Jun  2 22:30:45 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:30:45 2023 : Run ss scheduler
Fri Jun  2 22:30:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:30:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:30:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:30:46 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch73_model.tar
Fri Jun  2 22:30:47 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:30:47 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:30:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch73_best_val_acc_model.tar
Fri Jun  2 22:30:49 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch73_best_val_loss_model.tar
Fri Jun  2 22:30:49 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch73_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
73
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1554.126307606697
Attempted to log scalar metric secsPerRoundTotal:
146.17448687553406
Fri Jun  2 22:30:49 2023 : ==== iteration 74
Fri Jun  2 22:30:49 2023 : Client learning rate 0.1
Fri Jun  2 22:30:49 2023 : Clients for round 100
Fri Jun  2 22:32:38 2023 : Updating model
Fri Jun  2 22:32:38 2023 : Updating learning rate scheduler
Fri Jun  2 22:32:38 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:32:38 2023 : Run ss scheduler
Fri Jun  2 22:32:38 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:32:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:32:39 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:32:39 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch74_model.tar
Fri Jun  2 22:32:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:32:40 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:32:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch74_best_val_acc_model.tar
Fri Jun  2 22:32:42 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch74_best_val_loss_model.tar
Fri Jun  2 22:32:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch74_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
74
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1251.0773221254349
Attempted to log scalar metric secsPerRoundTotal:
113.45831036567688
Fri Jun  2 22:32:43 2023 : ==== iteration 75
Fri Jun  2 22:32:43 2023 : Client learning rate 0.1
Fri Jun  2 22:32:43 2023 : Clients for round 100
Fri Jun  2 22:34:48 2023 : Updating model
Fri Jun  2 22:34:48 2023 : Updating learning rate scheduler
Fri Jun  2 22:34:48 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:34:48 2023 : Run ss scheduler
Fri Jun  2 22:34:48 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:34:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:34:49 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:34:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch75_model.tar
Fri Jun  2 22:34:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:34:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:34:51 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch75_best_val_acc_model.tar
Fri Jun  2 22:34:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch75_best_val_loss_model.tar
Fri Jun  2 22:34:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch75_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
75
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1356.2792142629623
Attempted to log scalar metric secsPerRoundTotal:
129.81223917007446
Fri Jun  2 22:34:53 2023 : ==== iteration 76
Fri Jun  2 22:34:53 2023 : Client learning rate 0.1
Fri Jun  2 22:34:53 2023 : Clients for round 100
Fri Jun  2 22:36:53 2023 : Updating model
Fri Jun  2 22:36:53 2023 : Updating learning rate scheduler
Fri Jun  2 22:36:53 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:36:53 2023 : Run ss scheduler
Fri Jun  2 22:36:53 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:36:54 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:36:55 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:36:55 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch76_model.tar
Fri Jun  2 22:36:55 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:36:55 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:36:56 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch76_best_val_acc_model.tar
Fri Jun  2 22:36:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch76_best_val_loss_model.tar
Fri Jun  2 22:36:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch76_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
76
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1244.9227859973907
Attempted to log scalar metric secsPerRoundTotal:
125.48760604858398
Fri Jun  2 22:36:58 2023 : ==== iteration 77
Fri Jun  2 22:36:58 2023 : Client learning rate 0.1
Fri Jun  2 22:36:58 2023 : Clients for round 100
Fri Jun  2 22:39:21 2023 : Updating model
Fri Jun  2 22:39:21 2023 : Updating learning rate scheduler
Fri Jun  2 22:39:21 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:39:21 2023 : Run ss scheduler
Fri Jun  2 22:39:21 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:39:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:39:22 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:39:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch77_model.tar
Fri Jun  2 22:39:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:39:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:39:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch77_best_val_acc_model.tar
Fri Jun  2 22:39:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch77_best_val_loss_model.tar
Fri Jun  2 22:39:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch77_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
77
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1552.2005803585052
Attempted to log scalar metric secsPerRoundTotal:
147.48251628875732
Fri Jun  2 22:39:25 2023 : ==== iteration 78
Fri Jun  2 22:39:25 2023 : Client learning rate 0.1
Fri Jun  2 22:39:25 2023 : Clients for round 100
Fri Jun  2 22:41:36 2023 : Updating model
Fri Jun  2 22:41:36 2023 : Updating learning rate scheduler
Fri Jun  2 22:41:36 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:41:36 2023 : Run ss scheduler
Fri Jun  2 22:41:36 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:41:37 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:41:37 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:41:37 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch78_model.tar
Fri Jun  2 22:41:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:41:38 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:41:39 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch78_best_val_acc_model.tar
Fri Jun  2 22:41:40 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch78_best_val_loss_model.tar
Fri Jun  2 22:41:41 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch78_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
78
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1424.755003452301
Attempted to log scalar metric secsPerRoundTotal:
135.16954803466797
Fri Jun  2 22:41:41 2023 : ==== iteration 79
Fri Jun  2 22:41:41 2023 : Client learning rate 0.1
Fri Jun  2 22:41:41 2023 : Clients for round 100
Fri Jun  2 22:43:40 2023 : Updating model
Fri Jun  2 22:43:40 2023 : Updating learning rate scheduler
Fri Jun  2 22:43:40 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:43:40 2023 : Run ss scheduler
Fri Jun  2 22:43:40 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:43:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:43:41 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:43:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch79_model.tar
Fri Jun  2 22:43:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:43:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:43:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch79_best_val_acc_model.tar
Fri Jun  2 22:43:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch79_best_val_loss_model.tar
Fri Jun  2 22:43:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch79_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
79
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1156.937222957611
Attempted to log scalar metric secsPerRoundTotal:
124.32157492637634
Fri Jun  2 22:43:45 2023 : ==== iteration 80
Fri Jun  2 22:43:45 2023 : Client learning rate 0.1
Fri Jun  2 22:43:45 2023 : Clients for round 100
Fri Jun  2 22:45:41 2023 : Updating model
Fri Jun  2 22:45:41 2023 : Updating learning rate scheduler
Fri Jun  2 22:45:41 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:45:41 2023 : Run ss scheduler
Fri Jun  2 22:45:41 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:45:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:45:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:45:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch80_model.tar
Fri Jun  2 22:45:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:45:42 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:45:43 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch80_best_val_acc_model.tar
Fri Jun  2 22:45:44 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch80_best_val_loss_model.tar
Fri Jun  2 22:45:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch80_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
80
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
980.8493392467499
Attempted to log scalar metric secsPerRoundTotal:
119.91403341293335
Fri Jun  2 22:45:45 2023 : ==== iteration 81
Fri Jun  2 22:45:45 2023 : Client learning rate 0.1
Fri Jun  2 22:45:45 2023 : Clients for round 100
Fri Jun  2 22:48:27 2023 : Updating model
Fri Jun  2 22:48:27 2023 : Updating learning rate scheduler
Fri Jun  2 22:48:27 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:48:27 2023 : Run ss scheduler
Fri Jun  2 22:48:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:48:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:48:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:48:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch81_model.tar
Fri Jun  2 22:48:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:48:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:48:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch81_best_val_acc_model.tar
Fri Jun  2 22:48:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch81_best_val_loss_model.tar
Fri Jun  2 22:48:32 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch81_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
81
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1712.350482583046
Attempted to log scalar metric secsPerRoundTotal:
167.19590020179749
Fri Jun  2 22:48:32 2023 : ==== iteration 82
Fri Jun  2 22:48:32 2023 : Client learning rate 0.1
Fri Jun  2 22:48:32 2023 : Clients for round 100
Fri Jun  2 22:50:26 2023 : Updating model
Fri Jun  2 22:50:26 2023 : Updating learning rate scheduler
Fri Jun  2 22:50:26 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:50:26 2023 : Run ss scheduler
Fri Jun  2 22:50:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:50:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:50:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:50:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch82_model.tar
Fri Jun  2 22:50:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:50:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:50:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch82_best_val_acc_model.tar
Fri Jun  2 22:50:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch82_best_val_loss_model.tar
Fri Jun  2 22:50:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch82_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
82
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1160.9617083072662
Attempted to log scalar metric secsPerRoundTotal:
118.35739660263062
Fri Jun  2 22:50:30 2023 : ==== iteration 83
Fri Jun  2 22:50:30 2023 : Client learning rate 0.1
Fri Jun  2 22:50:30 2023 : Clients for round 100
Fri Jun  2 22:52:56 2023 : Updating model
Fri Jun  2 22:52:56 2023 : Updating learning rate scheduler
Fri Jun  2 22:52:56 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:52:56 2023 : Run ss scheduler
Fri Jun  2 22:52:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:52:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:52:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:52:57 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch83_model.tar
Fri Jun  2 22:52:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:52:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:52:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch83_best_val_acc_model.tar
Fri Jun  2 22:52:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch83_best_val_loss_model.tar
Fri Jun  2 22:53:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch83_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
83
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1395.0656543970108
Attempted to log scalar metric secsPerRoundTotal:
149.94943690299988
Fri Jun  2 22:53:00 2023 : ==== iteration 84
Fri Jun  2 22:53:00 2023 : Client learning rate 0.1
Fri Jun  2 22:53:00 2023 : Clients for round 100
Fri Jun  2 22:55:27 2023 : Updating model
Fri Jun  2 22:55:27 2023 : Updating learning rate scheduler
Fri Jun  2 22:55:27 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:55:27 2023 : Run ss scheduler
Fri Jun  2 22:55:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:55:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:55:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:55:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch84_model.tar
Fri Jun  2 22:55:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:55:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:55:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch84_best_val_acc_model.tar
Fri Jun  2 22:55:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch84_best_val_loss_model.tar
Fri Jun  2 22:55:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch84_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
84
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1530.8289519548416
Attempted to log scalar metric secsPerRoundTotal:
150.69080138206482
Fri Jun  2 22:55:31 2023 : ==== iteration 85
Fri Jun  2 22:55:31 2023 : Client learning rate 0.1
Fri Jun  2 22:55:31 2023 : Clients for round 100
Fri Jun  2 22:58:14 2023 : Updating model
Fri Jun  2 22:58:14 2023 : Updating learning rate scheduler
Fri Jun  2 22:58:14 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 22:58:14 2023 : Run ss scheduler
Fri Jun  2 22:58:14 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 22:58:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:58:15 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:58:15 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch85_model.tar
Fri Jun  2 22:58:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:58:16 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 22:58:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch85_best_val_acc_model.tar
Fri Jun  2 22:58:18 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch85_best_val_loss_model.tar
Fri Jun  2 22:58:19 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch85_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
85
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1660.4183150529861
Attempted to log scalar metric secsPerRoundTotal:
167.56072545051575
Fri Jun  2 22:58:19 2023 : ==== iteration 86
Fri Jun  2 22:58:19 2023 : Client learning rate 0.1
Fri Jun  2 22:58:19 2023 : Clients for round 100
Fri Jun  2 23:01:03 2023 : Updating model
Fri Jun  2 23:01:03 2023 : Updating learning rate scheduler
Fri Jun  2 23:01:03 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:01:03 2023 : Run ss scheduler
Fri Jun  2 23:01:03 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:01:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:01:04 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:01:04 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch86_model.tar
Fri Jun  2 23:01:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:01:05 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:01:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch86_best_val_acc_model.tar
Fri Jun  2 23:01:06 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch86_best_val_loss_model.tar
Fri Jun  2 23:01:07 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch86_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
86
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1566.8962316513062
Attempted to log scalar metric secsPerRoundTotal:
168.69522380828857
Fri Jun  2 23:01:07 2023 : ==== iteration 87
Fri Jun  2 23:01:07 2023 : Client learning rate 0.1
Fri Jun  2 23:01:07 2023 : Clients for round 100
Fri Jun  2 23:04:07 2023 : Updating model
Fri Jun  2 23:04:07 2023 : Updating learning rate scheduler
Fri Jun  2 23:04:07 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:04:07 2023 : Run ss scheduler
Fri Jun  2 23:04:07 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:04:08 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:04:08 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:04:08 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch87_model.tar
Fri Jun  2 23:04:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:04:09 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:04:10 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch87_best_val_acc_model.tar
Fri Jun  2 23:04:11 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch87_best_val_loss_model.tar
Fri Jun  2 23:04:12 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch87_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
87
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1765.2504875659943
Attempted to log scalar metric secsPerRoundTotal:
184.24798440933228
Fri Jun  2 23:04:12 2023 : ==== iteration 88
Fri Jun  2 23:04:12 2023 : Client learning rate 0.1
Fri Jun  2 23:04:12 2023 : Clients for round 100
Fri Jun  2 23:06:27 2023 : Updating model
Fri Jun  2 23:06:27 2023 : Updating learning rate scheduler
Fri Jun  2 23:06:27 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:06:27 2023 : Run ss scheduler
Fri Jun  2 23:06:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:06:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:06:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:06:28 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch88_model.tar
Fri Jun  2 23:06:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:06:29 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:06:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch88_best_val_acc_model.tar
Fri Jun  2 23:06:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch88_best_val_loss_model.tar
Fri Jun  2 23:06:31 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch88_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
88
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1393.1698863506317
Attempted to log scalar metric secsPerRoundTotal:
139.79070663452148
Fri Jun  2 23:06:31 2023 : ==== iteration 89
Fri Jun  2 23:06:31 2023 : Client learning rate 0.1
Fri Jun  2 23:06:31 2023 : Clients for round 100
Fri Jun  2 23:09:54 2023 : Updating model
Fri Jun  2 23:09:54 2023 : Updating learning rate scheduler
Fri Jun  2 23:09:54 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:09:54 2023 : Run ss scheduler
Fri Jun  2 23:09:54 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:09:55 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:09:55 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:09:55 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch89_model.tar
Fri Jun  2 23:09:56 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:09:56 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:09:57 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch89_best_val_acc_model.tar
Fri Jun  2 23:09:58 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch89_best_val_loss_model.tar
Fri Jun  2 23:09:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch89_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
89
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1895.0308833122253
Attempted to log scalar metric secsPerRoundTotal:
207.42000579833984
Fri Jun  2 23:09:59 2023 : ==== iteration 90
Fri Jun  2 23:09:59 2023 : Client learning rate 0.1
Fri Jun  2 23:09:59 2023 : Clients for round 100
Fri Jun  2 23:12:30 2023 : Updating model
Fri Jun  2 23:12:30 2023 : Updating learning rate scheduler
Fri Jun  2 23:12:30 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:12:30 2023 : Run ss scheduler
Fri Jun  2 23:12:30 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:12:31 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:12:31 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:12:31 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch90_model.tar
Fri Jun  2 23:12:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:12:32 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:12:33 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch90_best_val_acc_model.tar
Fri Jun  2 23:12:34 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch90_best_val_loss_model.tar
Fri Jun  2 23:12:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch90_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
90
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1581.0090111494064
Attempted to log scalar metric secsPerRoundTotal:
156.23086643218994
Fri Jun  2 23:12:35 2023 : ==== iteration 91
Fri Jun  2 23:12:35 2023 : Client learning rate 0.1
Fri Jun  2 23:12:35 2023 : Clients for round 100
Fri Jun  2 23:14:42 2023 : Updating model
Fri Jun  2 23:14:42 2023 : Updating learning rate scheduler
Fri Jun  2 23:14:42 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:14:42 2023 : Run ss scheduler
Fri Jun  2 23:14:42 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:14:43 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:14:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:14:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch91_model.tar
Fri Jun  2 23:14:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:14:44 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:14:45 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch91_best_val_acc_model.tar
Fri Jun  2 23:14:46 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch91_best_val_loss_model.tar
Fri Jun  2 23:14:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch91_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
91
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1313.5239386558533
Attempted to log scalar metric secsPerRoundTotal:
131.82011651992798
Fri Jun  2 23:14:47 2023 : ==== iteration 92
Fri Jun  2 23:14:47 2023 : Client learning rate 0.1
Fri Jun  2 23:14:47 2023 : Clients for round 100
Fri Jun  2 23:16:23 2023 : Updating model
Fri Jun  2 23:16:23 2023 : Updating learning rate scheduler
Fri Jun  2 23:16:23 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:16:23 2023 : Run ss scheduler
Fri Jun  2 23:16:23 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:16:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:16:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:16:24 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch92_model.tar
Fri Jun  2 23:16:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:16:25 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:16:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch92_best_val_acc_model.tar
Fri Jun  2 23:16:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch92_best_val_loss_model.tar
Fri Jun  2 23:16:27 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch92_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
92
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
913.246403336525
Attempted to log scalar metric secsPerRoundTotal:
100.22079992294312
Fri Jun  2 23:16:27 2023 : ==== iteration 93
Fri Jun  2 23:16:27 2023 : Client learning rate 0.1
Fri Jun  2 23:16:27 2023 : Clients for round 100
Fri Jun  2 23:18:49 2023 : Updating model
Fri Jun  2 23:18:49 2023 : Updating learning rate scheduler
Fri Jun  2 23:18:49 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:18:49 2023 : Run ss scheduler
Fri Jun  2 23:18:49 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:18:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:18:50 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:18:50 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch93_model.tar
Fri Jun  2 23:18:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:18:51 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:18:52 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch93_best_val_acc_model.tar
Fri Jun  2 23:18:53 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch93_best_val_loss_model.tar
Fri Jun  2 23:18:54 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch93_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
93
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1379.7337431907654
Attempted to log scalar metric secsPerRoundTotal:
146.59215569496155
Fri Jun  2 23:18:54 2023 : ==== iteration 94
Fri Jun  2 23:18:54 2023 : Client learning rate 0.1
Fri Jun  2 23:18:54 2023 : Clients for round 100
Fri Jun  2 23:21:22 2023 : Updating model
Fri Jun  2 23:21:22 2023 : Updating learning rate scheduler
Fri Jun  2 23:21:22 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:21:22 2023 : Run ss scheduler
Fri Jun  2 23:21:22 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:21:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:21:23 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:21:23 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch94_model.tar
Fri Jun  2 23:21:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:21:24 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:21:24 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch94_best_val_acc_model.tar
Fri Jun  2 23:21:25 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch94_best_val_loss_model.tar
Fri Jun  2 23:21:26 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch94_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
94
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1419.1130946874619
Attempted to log scalar metric secsPerRoundTotal:
152.4400007724762
Fri Jun  2 23:21:26 2023 : ==== iteration 95
Fri Jun  2 23:21:26 2023 : Client learning rate 0.1
Fri Jun  2 23:21:26 2023 : Clients for round 100
Fri Jun  2 23:23:44 2023 : Updating model
Fri Jun  2 23:23:44 2023 : Updating learning rate scheduler
Fri Jun  2 23:23:44 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:23:44 2023 : Run ss scheduler
Fri Jun  2 23:23:44 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:23:45 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:23:45 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:23:45 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch95_model.tar
Fri Jun  2 23:23:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:23:46 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:23:47 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch95_best_val_acc_model.tar
Fri Jun  2 23:23:48 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch95_best_val_loss_model.tar
Fri Jun  2 23:23:49 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch95_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
95
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1485.1031999588013
Attempted to log scalar metric secsPerRoundTotal:
142.77635216712952
Fri Jun  2 23:23:49 2023 : ==== iteration 96
Fri Jun  2 23:23:49 2023 : Client learning rate 0.1
Fri Jun  2 23:23:49 2023 : Clients for round 100
Fri Jun  2 23:26:32 2023 : Updating model
Fri Jun  2 23:26:32 2023 : Updating learning rate scheduler
Fri Jun  2 23:26:32 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:26:32 2023 : Run ss scheduler
Fri Jun  2 23:26:32 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:26:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:26:33 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:26:33 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch96_model.tar
Fri Jun  2 23:26:34 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:26:34 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:26:35 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch96_best_val_acc_model.tar
Fri Jun  2 23:26:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch96_best_val_loss_model.tar
Fri Jun  2 23:26:36 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch96_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
96
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1525.0327800512314
Attempted to log scalar metric secsPerRoundTotal:
167.60304617881775
Fri Jun  2 23:26:36 2023 : ==== iteration 97
Fri Jun  2 23:26:36 2023 : Client learning rate 0.1
Fri Jun  2 23:26:36 2023 : Clients for round 100
Fri Jun  2 23:29:56 2023 : Updating model
Fri Jun  2 23:29:56 2023 : Updating learning rate scheduler
Fri Jun  2 23:29:56 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:29:56 2023 : Run ss scheduler
Fri Jun  2 23:29:56 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:29:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:29:57 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:29:57 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch97_model.tar
Fri Jun  2 23:29:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:29:58 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:29:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch97_best_val_acc_model.tar
Fri Jun  2 23:29:59 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch97_best_val_loss_model.tar
Fri Jun  2 23:30:00 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch97_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
97
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1659.0509819984436
Attempted to log scalar metric secsPerRoundTotal:
203.6268548965454
Fri Jun  2 23:30:00 2023 : ==== iteration 98
Fri Jun  2 23:30:00 2023 : Client learning rate 0.1
Fri Jun  2 23:30:00 2023 : Clients for round 100
Fri Jun  2 23:32:12 2023 : Updating model
Fri Jun  2 23:32:12 2023 : Updating learning rate scheduler
Fri Jun  2 23:32:12 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:32:12 2023 : Run ss scheduler
Fri Jun  2 23:32:12 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:32:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:32:13 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:32:13 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch98_model.tar
Fri Jun  2 23:32:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:32:14 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:32:15 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch98_best_val_acc_model.tar
Fri Jun  2 23:32:16 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch98_best_val_loss_model.tar
Fri Jun  2 23:32:17 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch98_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
98
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1309.239695906639
Attempted to log scalar metric secsPerRoundTotal:
136.46199536323547
Fri Jun  2 23:32:17 2023 : ==== iteration 99
Fri Jun  2 23:32:17 2023 : Client learning rate 0.1
Fri Jun  2 23:32:17 2023 : Clients for round 100
Fri Jun  2 23:34:26 2023 : Updating model
Fri Jun  2 23:34:26 2023 : Updating learning rate scheduler
Fri Jun  2 23:34:26 2023 : LR BEFORE lr_scheduler step: 1.0
Fri Jun  2 23:34:26 2023 : Run ss scheduler
Fri Jun  2 23:34:26 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/latest_model.tar
Fri Jun  2 23:34:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:34:27 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:34:27 2023 : Saving model to: /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch99_model.tar
Fri Jun  2 23:34:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:34:28 2023 : Write operation succeeded in 1 attempts
Fri Jun  2 23:34:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch99_best_val_acc_model.tar
Fri Jun  2 23:34:29 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch99_best_val_loss_model.tar
Fri Jun  2 23:34:30 2023 : Saved /nfs-share/aai30/projects/msrflute_ex/outputs/openImg/files/2023-06-02 19:18:08.240751/13c5-40a5/models/epoch99_best_test_acc_model.tar
Attempted to log scalar metric Current iteration:
99
Attempted to log scalar metric Clients for round:
100
Attempted to log scalar metric Training loss:
1275.692494750023
Attempted to log scalar metric secsPerRoundTotal:
133.72784638404846
Fri Jun  2 23:34:30 2023 : server terminated

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: ngongotaha: task 6: Exited with exit code 2
srun: error: ngongotaha: task 5: Exited with exit code 2

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: ngongotaha: task 7: Exited with exit code 2
1883253

kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
srun: error: mauao: task 1: Exited with exit code 2
1312974
